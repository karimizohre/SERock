{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fcKNzsKL24J",
    "outputId": "cbba473f-426b-4a17-a313-daf40e5a727a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-evaluation\n",
      "  Downloading sklearn_evaluation-0.7.8-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: ipython in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (7.29.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (5.1.0)\n",
      "Requirement already satisfied: parso in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (0.8.2)\n",
      "Requirement already satisfied: black in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (19.10b0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (3.4.3)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (2.11.3)\n",
      "Collecting ploomber-core>=0.0.4\n",
      "  Downloading ploomber_core-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: mistune in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (0.8.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (0.24.2)\n",
      "Requirement already satisfied: nbformat in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (5.1.3)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn-evaluation) (1.3.4)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from ploomber-core>=0.0.4->sklearn-evaluation) (6.0)\n",
      "Collecting posthog\n",
      "  Using cached posthog-2.1.2-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from ploomber-core>=0.0.4->sklearn-evaluation) (8.0.3)\n",
      "Requirement already satisfied: toml>=0.9.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from black->sklearn-evaluation) (0.10.2)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from black->sklearn-evaluation) (0.7.0)\n",
      "Requirement already satisfied: appdirs in c:\\programdata\\anaconda3\\lib\\site-packages (from black->sklearn-evaluation) (1.4.4)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from black->sklearn-evaluation) (2021.8.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from black->sklearn-evaluation) (21.2.0)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from black->sklearn-evaluation) (1.4.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->ploomber-core>=0.0.4->sklearn-evaluation) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (0.18.0)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (3.0.20)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (2.10.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (5.1.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (58.0.4)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->sklearn-evaluation) (0.7.5)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->sklearn-evaluation) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->sklearn-evaluation) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->sklearn-evaluation) (1.20.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->sklearn-evaluation) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->sklearn-evaluation) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->sklearn-evaluation) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->sklearn-evaluation) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->sklearn-evaluation) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->sklearn-evaluation) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->sklearn-evaluation) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->sklearn-evaluation) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat->sklearn-evaluation) (4.8.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->sklearn-evaluation) (0.18.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat->sklearn-evaluation) (228)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->sklearn-evaluation) (2021.3)\n",
      "Collecting monotonic>=1.5\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff<2.0.0,>=1.10.0\n",
      "  Using cached backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from posthog->ploomber-core>=0.0.4->sklearn-evaluation) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.0.4->sklearn-evaluation) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.0.4->sklearn-evaluation) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.0.4->sklearn-evaluation) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.0.4->sklearn-evaluation) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn-evaluation) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn-evaluation) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn-evaluation) (1.7.1)\n",
      "Installing collected packages: monotonic, backoff, posthog, tabulate, ploomber-core, sklearn-evaluation\n",
      "Successfully installed backoff-1.11.1 monotonic-1.6 ploomber-core-0.0.7 posthog-2.1.2 sklearn-evaluation-0.7.8 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001A43100EE80>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/05/d3/0741c739273cc0eeaf9915bcf4482f0afc6aa5391f8e75ce10f23b47418b/sklearn_evaluation-0.7.8-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "Dwfu9EqkL7jZ",
    "outputId": "8d83497c-f82c-4401-94d6-f2020acb386f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ZOHREK~1\\AppData\\Local\\Temp/ipykernel_12728/2758081817.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0muploaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "\n",
    "drive.mount\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyqDJ3z4MTUB"
   },
   "outputs": [],
   "source": [
    "# remained Works:  parameter tunning of initial Estimators of meta model, selection of final estimator,plot results of grid search, XGBoost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# compare ensemble to each standalone models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from numpy import where\n",
    "from scipy import stats\n",
    "import seaborn as sn\n",
    "from mpl_toolkits.axisartist.axislines import Subplot\n",
    "from xgboost import XGBRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn_evaluation import plot\n",
    "# import scikeras\n",
    "# from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAkjd4H8QtH5"
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    import io\n",
    "    df =pd.read_csv(io.BytesIO(uploaded['E.csv']))\n",
    "    # df =pd.read_csv('E:/MyPapers/Dr Freidooni2/data/E.csv')\n",
    "    # dfUCS =pd.read_csv('E:/MyPapers/Dr Freidooni2/data/UCS.csv')\n",
    "    dfUCS =pd.read_csv(io.BytesIO(uploaded['UCS.csv']))\n",
    "    # df = pd.read_excel (io.BytesIO(uploaded['E.csv'])) #place \"r\" before the path string to address special character, such as '\\'. Don't forget to put the file name at the end of the path + '.xlsx'\n",
    "    y=df['E']\n",
    "    yUCS=dfUCS['UCS']\n",
    "    X=df[['d','ne','vp','HBN']]\n",
    "#     print(X)\n",
    "    return X,y,yUCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGZZVnRlMG34",
    "outputId": "9d307067-2ac8-4427-eae6-0ea15ce5c911"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# print(uploaded['E.csv'])\n",
    "\n",
    "X, y,yUCS = get_dataset()\n",
    "# import tensorflow as tf\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "Cqn3lNLLaiO7",
    "outputId": "33e5d0ea-966d-4631-9d52-9f9b708888bd"
   },
   "outputs": [],
   "source": [
    "# !wget \"https://dl.freefontsfamily.com/download/Times-New-Roman.zip\"\n",
    "# !unzip \"download?family=Times-New-Roman\"\n",
    "uploaded = files.upload()\n",
    "!mv times_new_roman.ttf /usr/share/fonts/truetype/\n",
    "\n",
    "!fc-cache -f -v\n",
    "\n",
    "# from matplotlib import font_manager\n",
    "import matplotlib.font_manager\n",
    "font_files =matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "\n",
    "\n",
    "# font_dirs = ['C:/Windows/Fonts/']\n",
    "# font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    matplotlib.font_manager.fontManager.addfont(font_file)\n",
    "\n",
    "# fm = font_manager.font_manager\n",
    "# fm.get_cachedir()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQ3u0Y71Sp5f",
    "outputId": "53639b73-1424-4301-9d3e-6b10917bbc00"
   },
   "outputs": [],
   "source": [
    "[f.name for f in matplotlib.font_manager.fontManager.ttflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U5eN9y3ZPAWT",
    "outputId": "84706683-ede3-4a9e-81a7-f0490f5aab31"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# # set font\n",
    "plt.rcParams['font.family'] = 'Times New Roman Cyr'\n",
    "plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "\n",
    "# drive.mount('mntdrive/')\n",
    "Features = np.array([\"$\\gamma_d(kN/m^3)$\",\"$n_e$(%)\",\"$v_p$(m/s)\",\"HBN(kgf/$mm^2$)\"])\n",
    "from google.colab import drive\n",
    "drive.mount('/Figures')\n",
    "images_dir = '/'\n",
    "# y = np.array([3, 8, 1, 10])\n",
    "# print(type(X))\n",
    "XMatrix=X.to_numpy()\n",
    "type(y)\n",
    "type(yUCS)\n",
    "\n",
    "for i in range(4):\n",
    "  plt.hist(XMatrix[:,i].transpose(), bins = 7,density=True, color='b',  edgecolor='black')\n",
    "  plt.rc('font', size=16)          # controls default text sizes\n",
    "  plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "  plt.rc('ytick', labelsize=14)\n",
    "  plt.xlabel(Features[i])\n",
    "  plt.ylabel('Frequency')\n",
    "  mu, std = norm.fit(XMatrix[:,i])\n",
    "  # Plot the PDF.\n",
    "  xmin, xmax = plt.xlim()\n",
    "  x = np.linspace(xmin, xmax, 100)\n",
    "  # print(x)\n",
    "  p = norm.pdf(x, mu, std)\n",
    "  # print(p)\n",
    "  plt.plot(x, p, 'r', linewidth=2)\n",
    "  title = \"Mean = {:.2f}, Std Dev= {:.2f}, N=70\".format(mu, std)\n",
    "  plt.title(title)\n",
    "  \n",
    "  plt.show() \n",
    "  plt.savefig(f\"{images_dir}testFigure.jpg\")\n",
    "  # plt.savefig('Histogram.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "FUrGl58J3ZI2",
    "outputId": "708c1ebb-28ce-4c1e-f2db-eaaf2eed8f54"
   },
   "outputs": [],
   "source": [
    "# Features = np.array([\"E (GPa)\",\"UCS (MPa)\"])\n",
    "Features = np.array([\"UCS (MPa)\"])\n",
    "print(type(yUCS))\n",
    "yEArray=np.array(y)\n",
    "yUCSArray=np.array(yUCS)\n",
    "# y=np.concatenate((yEArray,yUCSArray),axis=0)\n",
    "# yMatrix=yEArray\n",
    "yMatrix=yUCSArray\n",
    "for i in range(1):\n",
    "  plt.hist(yMatrix.transpose(), bins = 7,density=True, color='b',  edgecolor='black')\n",
    "  plt.rc('font', size=16)          # controls default text sizes\n",
    "  plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "  plt.rc('ytick', labelsize=14)\n",
    "  plt.xlabel(Features[i])\n",
    "  plt.ylabel('Frequency')\n",
    "  mu, std = norm.fit(yMatrix)\n",
    "  # Plot the PDF.\n",
    "  xmin, xmax = plt.xlim()\n",
    "  x = np.linspace(xmin, xmax, 100)\n",
    "  # print(x)\n",
    "  p = norm.pdf(x, mu, std)\n",
    "  # print(p)\n",
    "  plt.plot(x, p, 'r', linewidth=2)\n",
    "  title = \"Mean = {:.2f}, Std Dev= {:.2f}, N=70\".format(mu, std)\n",
    "  plt.title(title)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdlwMlZ8ANFk"
   },
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "      SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "      SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "      return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0UVvhE9H-Yu"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sensitivity import sensitivityAnalysis\n",
    "# sensitivityValues={'d':[2.17,8.03],'ne':[22.01,25.78],'vp':[3759.79,5347.06],'HBN':[271.81,975.79]}\n",
    "# sa=sensitivityAnalysier(sensitivityValues,X)\n",
    "# sa.df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2IkTFV5SbN3"
   },
   "outputs": [],
   "source": [
    "# my function: find best parameters by grid search\n",
    "def get_bestParm(name,model,X,y,weights):\n",
    "    foldCount=3;\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     single metric\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "    refitValue=\"neg_mean_squared_error\"\n",
    "#     scoring = \"r2\"\n",
    "#     refitValue=True\n",
    "    if name=='SVR':\n",
    "        params={\n",
    "            \"gamma\": [0.001,0.01,0.1,1,10],\n",
    "                \"C\": [0.001,0.01,0.1,1,10,100],\n",
    "                \"epsilon\":[0.001,0.01,0.1,1,10]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params,scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        grid_search.fit(X,y)\n",
    "        parmsNames=['$\\gamma$','C','$\\epsilon$']\n",
    "        plot_search_results(grid_search,parmsNames)\n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='cart':\n",
    "        params={'splitter':('best','random'),\n",
    "            'max_depth' : [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "           'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10],\n",
    "           'min_weight_fraction_leaf':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           'max_features':('auto','log2','sqrt',None),\n",
    "           'max_leaf_nodes':[None,10,20,30,40,50,60,70,80,90] }\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                         scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        start_time=timer(None)\n",
    "        grid_search.fit(X,y)\n",
    "        timer(start_time)\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='kNN':\n",
    "        params={'n_neighbors':[2,4,6,8,10,12,14,16,18,20],'weights':['uniform','distance']}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                           scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        grid_search.fit(X,y)\n",
    "        if \"r2\" in scoring:\n",
    "            plot_grid_search(grid_search,\n",
    "                                 'r2',\n",
    "                                 params['n_neighbors'], \n",
    "                                 params['weights'],\n",
    "                                 'k',\n",
    "                                 'weights',[10,2])\n",
    "        if \"neg_mean_squared_error\" in scoring:\n",
    "            plot_grid_search(grid_search,\n",
    "                                 'neg_mean_squared_error',\n",
    "                                 params['n_neighbors'], \n",
    "                                 params['weights'],\n",
    "                                 'k',\n",
    "                                 'weights',[10,2])\n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='RF':\n",
    "        params={'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    "                'n_estimators':[200,300,400,500]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        grid_search.fit(X,y)\n",
    "        legendLabel=['Estimatior#: 200', 'Estimatior#: 300', 'Estimatior#: 400', 'Estimatior#: 500']\n",
    "        newPlot_grid_search(grid_search,\n",
    "                                 'neg_mean_squared_error',\n",
    "                                 params['max_depth'], \n",
    "                                 params['n_estimators'],\n",
    "                                ['max_depth','n_estimators'],\n",
    "                                 'Maximum tree depth',\n",
    "                                 'Estimators#',[11,10],legendLabel)\n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='MLP':\n",
    "        params={\n",
    "            'solver' : ['lbfgs',  'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "            (7,),(8,),(9,),(10,),(11,),(12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,)\n",
    "             ]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        grid_search.fit(X,y)\n",
    "        legendLabel=['Solver: Adam', 'Solver: L-BFGS']\n",
    "        newPlot_grid_search(grid_search,\n",
    "                             'neg_mean_squared_error',\n",
    "                               [7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "                                        ['L-BFGS','Adam'],['hidden_layer_sizes','solver'],\n",
    "                             'Hidden Layer Sizes',\n",
    "                                 'Solver',[3,11],legendLabel)\n",
    "        \n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='MLP2':\n",
    "            params={\n",
    "                'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "                'hidden_layer_sizes': [\n",
    "                 (1,2),(2,2),(3,2),(4,2),(5,2),(6,2),(7,2),(8,2),(9,2),(10,2),\n",
    "                    (1,3),(2,3),(3,3),(4,3),(5,3),(6,3),(7,3),(8,3),(9,3),(10,3),\n",
    "                    (1,4),(2,4),(3,4),(4,4),(5,4),(6,4),(7,4),(8,4),(9,4),(10,4),\n",
    "                    (1,5),(2,5),(3,5),(4,5),(5,5),(6,5),(7,5),(8,5),(9,5),(10,5)\n",
    "                 ]}\n",
    "            grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                              scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "            grid_search.fit(X,y)\n",
    "            if \"r2\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                     'r2',\n",
    "                                     params['hidden_layer_sizes'], \n",
    "                                     params['solver'],\n",
    "                                     'Hidden Layer Sizes',\n",
    "                                     'Solver')\n",
    "            plot_grid_search(grid_search,\n",
    "                                 'neg_mean_squared_error',\n",
    "                                 params['hidden_layer_sizes'], \n",
    "                                 params['solver'],\n",
    "                                 'hidden_layer_sizes',\n",
    "                                 'solver')\n",
    "            print(\"{{{{{{}}}}}}\")\n",
    "            print(grid_search.best_estimator_)\n",
    "            return grid_search.best_estimator_\n",
    "    elif name=='XGBoost':\n",
    "            params={\n",
    "                'n_estimators' : [400,600,800,1000, 1200,1400,1600,1800, 2000],\n",
    "                'max_depth': [5,10, 20,30,40,50, 60, 70, 80, 90, 100],\n",
    "            'learning_rate':[0.01, 0.1, 0.2, 0.3,0.4, 0.5,0.6,0.7,0.8,0.9]}\n",
    "            grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                              scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "            grid_search.fit(X,y)\n",
    "            parmsNames=['Estimators#','Maximum tree depth','Learning rate']\n",
    "            plot_search_results(grid_search, parmsNames)\n",
    "            print(\"{{{{{{}}}}}}\")\n",
    "            print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "            print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "            print(grid_search.best_estimator_)\n",
    "            return grid_search.best_estimator_\n",
    "\n",
    "    elif name=='stacking':\n",
    "        model.fit(X,y)\n",
    "        return model\n",
    "    elif name=='stacking_SVM':\n",
    "\n",
    "        params={\n",
    "            'final_estimator__gamma':[0.001,0.01,0.1,1,10,100],\n",
    "            'final_estimator__C': [ 0.001,0.01,0.1,1,10],\n",
    "            'final_estimator__epsilon':[0.001,0.01,0.1,1,10],\n",
    "        }\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        \n",
    "        parmsNames=['$\\gamma$','C','$\\epsilon$']\n",
    "        grid_search.fit(X,y)\n",
    "        plot_search_results(grid_search,parmsNames)\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        return grid_search.best_estimator_ \n",
    "    elif name=='stacking_XGB':\n",
    "        print('model:')\n",
    "        print(model)\n",
    "        print('parms:')\n",
    "        print(model.get_params().keys())\n",
    "        params={\n",
    "            'final_estimator__n_estimators' : [400,600,800,1000, 1200,1400,1600,1800, 2000],\n",
    "            'final_estimator__max_depth': [5,10, 20,30,40,50, 60, 70, 80, 90, 100],\n",
    "            'final_estimator__learning_rate':[0.01, 0.1, 0.2, 0.3,0.4, 0.5,0.6,0.7,0.8,0.9]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        grid_search.fit(X,y)\n",
    "        if len(params)<=2:\n",
    "            if \"r2\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                     'r2',\n",
    "                                     params['final_estimator__n_estimators'], \n",
    "                                     params['final_estimator__learning_rate'],\n",
    "                                     'Estimators#',\n",
    "                                     'Learning Rate',[9,10,11])\n",
    "            if \"neg_mean_squared_error\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                     'neg_mean_squared_error',\n",
    "                                     params['final_estimator__n_estimators'], \n",
    "                                     params['final_estimator__learning_rate'],\n",
    "                                     'Estimators#',\n",
    "                                     'Learning Rate',[9,10,11])\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='stacked_XGB':\n",
    "        params={\n",
    "            'final_estimator__n_estimators' : [400,800, 1200,1600, 2000],\n",
    "            'final_estimator__max_depth': [5,10, 20,40, 60,  80,  100],\n",
    "        'final_estimator__learning_rate':[0.01,  0.2, 0.4, 0.6,0.8]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        grid_search.fit(X,y)\n",
    "        if len(params)<=2:\n",
    "            if \"r2\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                  'r2',\n",
    "                                  params['n_estimators'], \n",
    "                                  params['max_depth'],\n",
    "                                  'Estimators#',\n",
    "                                  'Max Depth',\n",
    "                                 [5,7,5])\n",
    "            if \"neg_mean_squared_error\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                  'neg_mean_squared_error',\n",
    "                                  params['n_estimators'], \n",
    "                                  params['max_depth'],\n",
    "                                  'Estimators#',\n",
    "                                  'Max Depth',[5,7,5])\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='stacking_MLP':\n",
    "\n",
    "        params={\n",
    "            'final_estimator__solver' : ['lbfgs', 'adam'],\n",
    "            'final_estimator__hidden_layer_sizes': [               \n",
    "            #  (1,),(2,),(3,),(4,),(5,),(6,),\n",
    "            (7,),(8,),(9,),(10,),(11,),(12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,)\n",
    "             ]}      \n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3, )      \n",
    "        grid_search.fit(X,y)\n",
    "        legendLabel=[ 'Solver: L-BFGS','Solver: Adam']\n",
    "        newPlot_grid_search(grid_search,\n",
    "                             'neg_mean_squared_error',\n",
    "                               [7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "                                        ['L-BFGS','Adam'],['final_estimator__hidden_layer_sizes','final_estimator__solver'],\n",
    "                            'Hidden Layer Sizes','Solver',[20,20],legendLabel)\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        return grid_search.best_estimator_  \n",
    "    else:   \n",
    "        model.fit(X,y)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE74UtzMjmOV"
   },
   "outputs": [],
   "source": [
    "def plot_search_results(grid, parmNames):\n",
    "    \"\"\"\n",
    "    Params: \n",
    "        grid: A trained GridSearchCV object.\n",
    "        parmNames: parmameter names for displaying in Figure\n",
    "    \"\"\"\n",
    "    ## Results from grid search\n",
    "    results = grid.cv_results_\n",
    "    means_test = results['mean_test_score']\n",
    "    stds_test = results['std_test_score']\n",
    "    # means_train = results['mean_train_score']\n",
    "    # stds_train = results['std_train_score']\n",
    "\n",
    "    ## Getting indexes of values per hyper-parameter\n",
    "    masks=[]\n",
    "    masks_names= list(grid.best_params_.keys())\n",
    "    # masks_names=parmNames\n",
    "    for p_k, p_v in grid.best_params_.items():\n",
    "        masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "    params=grid.param_grid\n",
    "\n",
    "    ## Ploting results\n",
    "    fig, ax = plt.subplots(1,len(params),sharex='none', sharey='all',figsize=(20,5))\n",
    "    # fig.suptitle('Score per parameter')\n",
    "    fig.text(0.04, 0.5, 'Negative MSE', va='center', rotation='vertical')\n",
    "    fig.text(0.04, 0.5, 'Negative MSE', va='center', rotation='vertical')\n",
    "    pram_preformace_in_best = {}\n",
    "    for i, p in enumerate(masks_names):\n",
    "        m = np.stack(masks[:i] + masks[i+1:])\n",
    "        pram_preformace_in_best\n",
    "        best_parms_mask = m.all(axis=0)\n",
    "        best_index = np.where(best_parms_mask)[0]\n",
    "        x = np.array(params[p])\n",
    "        y_1 = np.array(means_test[best_index])\n",
    "        e_1 = np.array(stds_test[best_index])\n",
    "        # y_2 = np.array(means_train[best_index])\n",
    "        # e_2 = np.array(stds_train[best_index])\n",
    "        ax[i].errorbar(x, y_1, e_1, linestyle='-', marker='o', label='test')\n",
    "        # ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "        # ax[i].set_xlabel(p.upper())\n",
    "        ax[i].set_xlabel(parmNames[i])\n",
    "\n",
    "    # plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISUW4Wm_QvBr"
   },
   "outputs": [],
   "source": [
    "def newPlot_grid_search(grid_search, metric, grid_param_1, grid_param_2, originalParmNames,name_param_1, name_param_2,ColumnsCount,legendLabel):\n",
    "   \n",
    "    \n",
    "    cv_results=grid_search.cv_results_\n",
    "    \n",
    "    _, ax = plt.subplots()\n",
    "    ax.set_frame_on(True)\n",
    "    ax.tick_params(direction='out')\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.set_axis_on()\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "    plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "    plt.grid(False)\n",
    "    coefficient=-1\n",
    "    metricLabel='Negative MSE'\n",
    "    if metric=='r2':    \n",
    "      coefficient=1 \n",
    "      metricLabel=\"$R^2$\" \n",
    "    ax.set_frame_on(True)\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "\n",
    "\n",
    "    print('originalParmNames[0]={0}'.format(originalParmNames[0]))\n",
    "    print('gridParm1={0}'.format(grid_param_1))\n",
    "    print('name_param_1={0}'.format(name_param_1))\n",
    "\n",
    "    ax=plot.grid_search(grid_search.cv_results_, (originalParmNames[0]),None,'line',None,ax)\n",
    "    ax.set_xticklabels(grid_param_1)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "          fancybox=True, shadow=True, ncol=np.min([ColumnsCount[0],2]), prop={'family': 'Times New Roman Cyr'}, fontsize=14,labels=legendLabel)\n",
    "    \n",
    "    ax.set_xlabel(name_param_1, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    plt.xlabel(name_param_1)\n",
    "    \n",
    "    ax.set_ylabel( metricLabel, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    plt.title('')\n",
    "    plt.show()    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwKvcUwwSlRP"
   },
   "outputs": [],
   "source": [
    "def plot_grid_search(grid_search, metric, grid_param_1, grid_param_2, name_param_1, name_param_2,ColumnsCount):\n",
    "\n",
    "    \n",
    "    # print(grid_search.grid_scores_)\n",
    "    cv_results=grid_search.cv_results_\n",
    "    # print(cv_results)\n",
    "    # Get Test Scores Mean and std for each grid search\n",
    "    # scores_mean = cv_results[('mean_test_' + metric)]\n",
    "    # scores_sd = cv_results[('std_test_' + metric)]\n",
    "    scores_mean = cv_results['mean_test_score']\n",
    "    print('cv_results.best_score_={0}'.format(grid_search.best_score_))\n",
    "    print('cv_results.best_params_={0}'.format(grid_search.best_params_))\n",
    "    print('cv_results[mean_test_score]={0}'.format( cv_results['mean_test_score']))\n",
    "    print('cv_results[mean_train_score]={0}'.format( cv_results['mean_train_score']))\n",
    "    cv_resultsDf = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "    print('data frame ='.format(cv_resultsDf))\n",
    "    scores_df=pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    print('best row'.format(best_row['mean_test_score']))\n",
    "    scores_sd = cv_results['std_test_score']\n",
    "    print(pd.DataFrame(cv_results).loc[:, ['mean_test_score', 'rank_test_score']].sort_values(by='rank_test_score'))    \n",
    "\n",
    "    if grid_param_2 is not None:\n",
    "        scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "        scores_sd = np.array(scores_sd).reshape(len(grid_param_2),len(grid_param_1))\n",
    "    print('scores_mean:')\n",
    "    print(scores_mean)\n",
    "    # Set plot style\n",
    "#     plt.style.use('seaborn')\n",
    "    \n",
    "#     plt.rcParams['axes.edgecolor'] = 'black'\n",
    "    # Plot Grid search scores\n",
    "    _, ax = plt.subplots()\n",
    "    ax.set_frame_on(True)\n",
    "    ax.tick_params(direction='out')\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.set_axis_on()\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "    plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "    plt.grid(False)\n",
    "    coefficient=-1\n",
    "    metricLabel='MSE'\n",
    "    if metric=='r2':    \n",
    "      coefficient=1 \n",
    "      metricLabel=\"$R^2$\" \n",
    "    if grid_param_2 is not None:\n",
    "        # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "        for idx, val in enumerate(grid_param_2):\n",
    "            ax.plot(grid_param_1,coefficient*scores_mean[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "          fancybox=True, shadow=True, ncol=np.min([ColumnsCount[1],2]), prop={'family': 'Times New Roman Cyr'}, fontsize=14)\n",
    "    else:\n",
    "        # If only one Param1 is given\n",
    "        ax.plot(grid_param_1, coefficient*scores_mean, '-o',label=name_param_1)\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "          fancybox=True, shadow=True, ncol=np.min([ColumnsCount[0],3]), prop={'family': 'Times New Roman Cyr'}, fontsize=14)\n",
    "\n",
    "    # only for MLP\n",
    "    if name_param_1=='Hidden Layer Sizes':\n",
    "      plt.xticks(grid_param_1)\n",
    "\n",
    "    ax.set_frame_on(True)\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "    ax.set_xlabel(name_param_1, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    \n",
    "    # ax.set_ylabel('CV ' + str.capitalize(metric), fontsize=16 , fontweight='normal')\n",
    "    ax.set_ylabel( metricLabel, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfeuzGo_S3GP"
   },
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    seed = np.random.seed(22)\n",
    "    rng = np.random.RandomState(1)\n",
    "    models = dict()\n",
    "    models['XGBoost'] = XGBRegressor()\n",
    "    # models['kNN'] = KNeighborsRegressor()   \n",
    "    models['MLP'] = MLPRegressor(max_iter=2000, random_state=1)\n",
    "    models['SVR'] = SVR(kernel='rbf' )\n",
    "    models['RF'] = RandomForestRegressor(random_state=rng)\n",
    "\n",
    "    #  models['LR'] = LinearRegression()\n",
    "    # models['MLP2'] = MLPRegressor(max_iter=2000, random_state=1)\n",
    "    # models['cart'] = DecisionTreeRegressor()\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import tensorflow as tf\n",
    "\n",
    "    from keras import backend as K\n",
    "\n",
    "    def coeff_determination(y_true, y_pred):\n",
    "      SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "      SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "      return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfMHeQstS8L4"
   },
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model,X_train, X_test, y_train, y_test):\n",
    "    history=model.fit(X_train,y_train)\n",
    "    yhatTrain=model.predict(X_train)\n",
    "    yhat=model.predict(X_test)\n",
    "    mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "    mse = metrics.mean_squared_error(y_test, yhat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_test,yhat)\n",
    "    return yhat,mae,mse,rmse,r2,history,yhatTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "wgqLTX9KRGng",
    "outputId": "425a74ba-4765-4f45-a6a8-0aaadcf4d320"
   },
   "outputs": [],
   "source": [
    "dim=4\n",
    "arrayX=X.to_numpy()\n",
    "arrayY=y.to_numpy()\n",
    "arrayyUCS=yUCS.to_numpy()\n",
    "# Sensitivity Analysis\n",
    "rr=[0,0,0,0]\n",
    "for j in range(dim):\n",
    "  temp=arrayX[:,j]*arrayY[:]\n",
    "  temp1=np.power(arrayX[:,j],2)\n",
    "  temp2=np.power(arrayY,2)\n",
    "  rr[j]=(np.sum(temp)/np.sqrt(np.sum(temp1)*np.sum(temp2)))\n",
    "  \n",
    "# print(rr)\n",
    "\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "c = ['red', 'green', 'orange', 'blue']\n",
    "# ax.bar(['$\\gamma_d$','$n_e$','$v_p$','HBN'], rr, width=0.8, edgecolor=\"white\",color=c, linewidth=0.5)\n",
    "ax.bar(['$\\gamma_d$','$n_e$','$v_p$','HBN'], rr, width=0.8, edgecolor=\"white\",color=c, linewidth=0.5)\n",
    "for index,data in enumerate(rr):\n",
    "    plt.text(x=index-0.02,y=data+0.005, s= \"{:.2f}\".format(data) , fontdict=dict(fontsize=14))\n",
    "ax.set( ylim=(0.6, 1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot for yUCS\n",
    "rr=[0,0,0,0]\n",
    "for j in range(dim):\n",
    "  temp=arrayX[:,j]*arrayyUCS[:]\n",
    "  temp1=np.power(arrayX[:,j],2)\n",
    "  temp2=np.power(arrayyUCS,2)\n",
    "  rr[j]=(np.sum(temp)/np.sqrt(np.sum(temp1)*np.sum(temp2)))\n",
    "print(rr)\n",
    "  # plot\n",
    "fig, ax = plt.subplots()\n",
    "# c = ['red', 'green', 'orange', 'blue']\n",
    "ax.bar(['$\\gamma_d$','$n_e$','$v_p$','HBN'], rr, width=0.8, edgecolor=\"white\",color=c, linewidth=0.5)\n",
    "for index,data in enumerate(rr):\n",
    "    plt.text(x=index-0.02,y=data+0.005, s= \"{:.2f}\".format(data) , fontdict=dict(fontsize=14))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1kQWUD3THns"
   },
   "outputs": [],
   "source": [
    "def runBaseAlgorithms(X,y):# type(X)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "  print(X_train.shape)\n",
    "  from sklearn.preprocessing import MinMaxScaler\n",
    "  scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "  scalarX.fit(X_train)\n",
    "  # scalarY.fit(y_train.values.reshape(-1,1))\n",
    "  X_train = scalarX.transform(X_train)\n",
    "  \n",
    "  # get the models to evaluate\n",
    "  models = get_models()\n",
    "  print('models='.format(models))\n",
    "  # evaluate the models and store results\n",
    "  results, names = list(), list()\n",
    "  i=1\n",
    "  for name, model in models.items():\n",
    "      tunnedModel=get_bestParm(name,model,X_train,y_train.ravel(),[])\n",
    "      models[name]=tunnedModel\n",
    "      print('&&&&')\n",
    "      print(tunnedModel)\n",
    "      print('&&&&')\n",
    "          \n",
    "  \n",
    "  print(models)\n",
    "  predictedY=np.zeros((len(models),len(y_test)))\n",
    "  PredictedYTrain=np.zeros((len(models),len(y_train)))\n",
    "    # np.zeros((len(models),len(y_train)))\n",
    "  mae=dict()\n",
    "  mse=dict()\n",
    "  rmse=dict()\n",
    "  r2=dict()\n",
    "  maeTrain=dict()\n",
    "  mseTrain=dict()\n",
    "  rmseTrain=dict()\n",
    "  r2Train=dict() \n",
    "\n",
    "  i=0\n",
    "  X_test  = scalarX.transform(X_test)\n",
    "  for name, model in models.items():\n",
    "      predictedYModel,mae[name],mse[name],rmse[name],r2[name],history,yhatTrain = evaluate_model(model,X_train, X_test, y_train.ravel(), y_test.ravel())\n",
    "\n",
    "      maeTrain[name] = metrics.mean_absolute_error(y_train.ravel(), yhatTrain)\n",
    "      mseTrain[name] = metrics.mean_squared_error(y_train.ravel(), yhatTrain)\n",
    "      rmseTrain [name]= np.sqrt(mseTrain[name])\n",
    "      r2Train[name] = metrics.r2_score(y_train.ravel(),yhatTrain)\n",
    "\n",
    "      PredictedYTrain[i,:]=yhatTrain\n",
    "      # PredictedYTrain[name]=yhatTrain\n",
    "      # print(yhatTrain.shape)\n",
    "      # print(y_train.shape)\n",
    "      # print('---yhatTrain')\n",
    "      # print(yhatTrain)\n",
    "      # print('---y_train')\n",
    "      # print(y_train.ravel())\n",
    "      # print('---')\n",
    "      absoluteError=np.absolute(yhatTrain-y_train.ravel())\n",
    "      normalizedAbsoluteError=absoluteError/(np.max(absoluteError)+0.00001)\n",
    "      # print(normalizedAbsoluteError)\n",
    "      # weights = np.zeros((1,len(yhatTrain)))\n",
    "      weights=normalizedAbsoluteError/(1-normalizedAbsoluteError)\n",
    "      print('---')\n",
    "      if name=='DNN':\n",
    "        print(predictedYModel.shape)\n",
    "        predictedYModel=predictedYModel.reshape(len(y_test),)\n",
    "        print(predictedYModel.shape)\n",
    "      predictedY[i,:]=predictedYModel\n",
    "      results.append(rmse[name])\n",
    "      names.append(name)\n",
    "      print('>%s %.3f,%.3f,%.3f,%.3f' % (name, mae[name],mse[name],rmse[name],r2[name]))\n",
    "      i=i+1\n",
    "  return mae,mse,rmse,r2,normalizedAbsoluteError,weights,models,X_train,X_test,y_train,y_test,predictedY,PredictedYTrain, maeTrain, mseTrain,rmseTrain,r2Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4Jhk23a_-sh"
   },
   "outputs": [],
   "source": [
    "def GridSearch_table_plot(grid_clf, param_name,\n",
    "                          num_results=15,\n",
    "                          negative=True,\n",
    "                          graph=True,\n",
    "                          display_all_params=True):\n",
    "\n",
    "    '''Display grid search results\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "\n",
    "    grid_clf           the estimator resulting from a grid search\n",
    "                       for example: grid_clf = GridSearchCV( ...\n",
    "\n",
    "    param_name         a string with the name of the parameter being tested\n",
    "\n",
    "    num_results        an integer indicating the number of results to display\n",
    "                       Default: 15\n",
    "\n",
    "    negative           boolean: should the sign of the score be reversed?\n",
    "                       scoring = 'neg_log_loss', for instance\n",
    "                       Default: True\n",
    "\n",
    "    graph              boolean: should a graph be produced?\n",
    "                       non-numeric parameters (True/False, None) don't graph well\n",
    "                       Default: True\n",
    "\n",
    "    display_all_params boolean: should we print out all of the parameters, not just the ones searched for?\n",
    "                       Default: True\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "\n",
    "    GridSearch_table_plot(grid_clf, \"min_samples_leaf\")\n",
    "\n",
    "                          '''\n",
    "    from matplotlib      import pyplot as plt\n",
    "    from IPython.display import display\n",
    "    import pandas as pd\n",
    "\n",
    "    clf = grid_clf.best_estimator_\n",
    "    clf_params = grid_clf.best_params_\n",
    "    if negative:\n",
    "        clf_score = -grid_clf.best_score_\n",
    "    else:\n",
    "        clf_score = grid_clf.best_score_\n",
    "    clf_stdev = grid_clf.cv_results_['std_test_score'][grid_clf.best_index_]\n",
    "    cv_results = grid_clf.cv_results_\n",
    "\n",
    "    print(\"best parameters: {}\".format(clf_params))\n",
    "    print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n",
    "    if display_all_params:\n",
    "        import pprint\n",
    "        pprint.pprint(clf.get_params())\n",
    "\n",
    "    # pick out the best results\n",
    "    # =========================\n",
    "    scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    if negative:\n",
    "        best_mean = -best_row['mean_test_score']\n",
    "    else:\n",
    "        best_mean = best_row['mean_test_score']\n",
    "    best_stdev = best_row['std_test_score']\n",
    "    best_param = best_row['param_' + param_name]\n",
    "\n",
    "    # display the top 'num_results' results\n",
    "    # =====================================\n",
    "    display(pd.DataFrame(cv_results) \\\n",
    "            .sort_values(by='rank_test_score').head(num_results))\n",
    "\n",
    "    # plot the results\n",
    "    # ================\n",
    "    scores_df = scores_df.sort_values(by='param_' + param_name)\n",
    "\n",
    "    if negative:\n",
    "        means = -scores_df['mean_test_score']\n",
    "    else:\n",
    "        means = scores_df['mean_test_score']\n",
    "    stds = scores_df['std_test_score']\n",
    "    params = scores_df['param_' + param_name]\n",
    "\n",
    "    # plot\n",
    "    if graph:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.errorbar(params, means, yerr=stds)\n",
    "\n",
    "        plt.axhline(y=best_mean + best_stdev, color='red')\n",
    "        plt.axhline(y=best_mean - best_stdev, color='red')\n",
    "        plt.plot(best_param, best_mean, 'or')\n",
    "\n",
    "        plt.title(param_name + \" vs Score\\nBest Score {:0.5f}\".format(clf_score))\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Score')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5T8QzIQTVZ9a",
    "outputId": "7e001f60-5d8b-44d0-b442-5bc1bff228b1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mae,mse,rmse,r2,normalizedAbsoluteError,weights,models,X_train,X_test,y_train,y_test,predictedY,PredictedYTrain,maeTrainE, mseTrainE,rmseTrainE,r2TrainE=runBaseAlgorithms(X,y)\n",
    "maeyUCS,mseyUCS,rmseyUCS,r2yUCS,normalizedAbsoluteErroryUCS,weightsyUCS,modelsyUCS,X_train,X_test,y_trainyUCS,y_testyUCS,predictedyUCS,PredictedYTrainUCS,maeTrainUCS, mseTrainUCS,rmseTrainUCS,r2TrainUCS=runBaseAlgorithms(X,yUCS)\n",
    "\n",
    "\n",
    "# print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AY-EVSRTHk-s",
    "outputId": "bfd6641a-fcc3-4598-f582-ad8bd71f8a2e"
   },
   "outputs": [],
   "source": [
    "print(maeTrainE, mseTrainE,rmseTrainE,r2TrainE)\n",
    "# print(maeTrainUCS, mseTrainUCS,rmseTrainUCS,r2TrainUCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgtRS6XhGTnW",
    "outputId": "e58b04b5-59ac-4e65-9c0b-c7f60440f918"
   },
   "outputs": [],
   "source": [
    "for name in r2TrainE:\n",
    "  print(name,r2TrainE[name])\n",
    "for name in mseTrainE:\n",
    "  print(name,mseTrainE[name])\n",
    "# , mseTrainE,rmseTrainE,r2TrainE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16CtmyWTxpjL",
    "outputId": "be3d0b44-f991-4be3-efa9-4fa3566b00db"
   },
   "outputs": [],
   "source": [
    "for name in r2TrainUCS:\n",
    "  print(name,r2TrainUCS[name])\n",
    "for name in mseTrainUCS:\n",
    "  print(name,mseTrainUCS[name])\n",
    "# , mseTrainE,rmseTrainE,r2TrainE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO5GbX9jafbA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhEwO8qvkuuk"
   },
   "outputs": [],
   "source": [
    "# scores_mean=[[0.62879967, 0.65522623, 0.62041626, 0.64972037, 0.60425748 ,0.6534937,  0.56108763 ,0.63067605, 0.50905696, 0.59100625] [0.43925092, 0.55022683, 0.43260782, 0.53965881, 0.40668475 ,0.52305652 , 0.37584775 ,0.50523751 0.35346637 0.49098451]]\n",
    "# bestValue=np.amax(scores_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2r-2KeqwcFva"
   },
   "outputs": [],
   "source": [
    "def plotScatter(x,y,outputLabel,name,r2,offset):\n",
    "  _, ax = plt.subplots()\n",
    "  ax.set_frame_on(True)\n",
    "  ax.tick_params(direction='out')\n",
    "  ax.set_facecolor(\"white\")\n",
    "  ax.set_axis_on()\n",
    "  # plt.rcParams[\"legend.loc\"] = 'best'\n",
    "  plt.rcParams['axes.unicode_minus'] = False\n",
    "  plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "  plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "  plt.grid(False)\n",
    "  plt.plot(x, y, 'o')\n",
    "  m, b = np.polyfit(x, y, 1)\n",
    "  plt.plot(x, m*x + b)\n",
    "  plt.plot(x, x,'k',linestyle='dashed')\n",
    "  ax.set_xlabel(outputLabel+' (observed)', fontsize=14 , fontweight='normal')\n",
    "  ax.set_ylabel(outputLabel+ ' (predicted)', fontsize=14 , fontweight='normal')\n",
    "  plt.title(name, fontsize=14 , fontweight='normal')\n",
    "  #  str(m)+'*X+'+str(b)\n",
    "  relation=\"$R^2$={:.2f}\\nY={:.2f}X+{:.2f}\".format(r2,m, b)\n",
    "  ax.text(np.min(x)+offset[0], np.max(y)-offset[1], relation , fontsize=14 , fontweight='normal', fontfamily='Times New Roman Cyr')\n",
    "  # , bbox=dict(facecolor='red', alpha=0.5)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkrUA_H_0ddX"
   },
   "outputs": [],
   "source": [
    "# comment permanently\n",
    "# plotScatter(y_testyUCS,yhatUCS2,'UCS','Stacked Ensemble',r2UCS2,[1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRiABMjqwOOQ"
   },
   "outputs": [],
   "source": [
    "# print(sortedValues)\n",
    "# importantIdexes=sortedIdx[len(sortedIdx)-13:len(sortedIdx)]\n",
    "# print(importantIdexes)\n",
    "# print('--')\n",
    "# print(sortedIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOW-p7uVafVE",
    "outputId": "77e815a3-2ebf-44bc-c0c0-cdf03b8e4fb7"
   },
   "outputs": [],
   "source": [
    "# sorted_mse = dict( sorted(mse.items()))\n",
    "# print('Dictionary in descending order by value : ',sorted_mse)\n",
    "print('>sorted Results in MSE')\n",
    "{k: v for k, v in sorted(mse.items(), key=lambda item: item[1])}\n",
    "# print(sorted(mse.items()))\n",
    "# sorted_mse = dict( sorted(mse.items(), reverse=True))\n",
    "# print('Dictionary in descending order by value : ',sorted_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swke_S1Bansr",
    "outputId": "e921f1c6-ba55-45c4-e2cb-743f62c44dbb"
   },
   "outputs": [],
   "source": [
    "print('>sorted Results in R2')\n",
    "{k: v for k, v in sorted(r2.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBapokGc9kPU"
   },
   "outputs": [],
   "source": [
    "# \tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "# \treturn X,y\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking(models,metamodel):\n",
    "\t# define the base models\n",
    "    level0 = list()\n",
    "    for name,model in models.items():\n",
    "        level0.append((name, model))\n",
    "#     level0.append(('knn', models['knn']))\n",
    "#     level0.append(('MLP2', models['MLP2']))\n",
    "#     level0.append(('MLP', models['MLP']))\n",
    "#     level0.append(('cart', models['cart']))\n",
    "#     level0.append(('SVR',  models['SVR']))\n",
    "#     level0.append(('LR',  models['LR']))\n",
    "\t# define meta learner model\n",
    "#     level1=LinearRegression()\n",
    "#     level1 = RandomForestRegressor()\n",
    "#     level1 =SVR(kernel='rbf')\n",
    "    level1 =metamodel\n",
    "#     level1=MLPRegressor(max_iter=2000, random_state=1)\n",
    "#     MLPRegressor(max_iter=500);\n",
    "#     level1 = LinearRegression()\n",
    "\t# define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=3)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4q_3fNIc9yNL",
    "outputId": "5777d7ed-c142-46c0-a48e-4e08e9d1487d"
   },
   "outputs": [],
   "source": [
    "print('>sorted Results in MSE')\n",
    "{k: v for k, v in sorted(mse.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "IPwmdO0vZQ7Y",
    "outputId": "c8a7fd3d-39d4-44b4-a83b-9d1afdca8f75"
   },
   "outputs": [],
   "source": [
    "print(np.min(normalizedAbsoluteError))\n",
    "print(np.max(normalizedAbsoluteError))\n",
    "plt.plot(normalizedAbsoluteError*10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xwcg13rW99ZA"
   },
   "outputs": [],
   "source": [
    "def runStackedEnsemble(selectedModels,X_train,y_train,y_test,stackedName,metamodel):\n",
    "  \n",
    "  stackModel= get_stacking(selectedModels,metamodel)\n",
    "  # estimator = KerasRegressor(build_fn=stackModel, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "  print('***')\n",
    "  # print(estimator)\n",
    "  print('***')\n",
    "  print(stackModel.get_params().keys())\n",
    "  # tunnedModel=get_bestParm('stacking_SVM',stackModel ,X_train,y_train.ravel(),[])\n",
    "  print(stackedName)\n",
    "  tunnedModel=get_bestParm(stackedName,stackModel ,X_train,y_train.ravel(),[])\n",
    "  # print(tunnedModel)\n",
    "  # tunnedModel.fit(X_train,y_train.ravel())\n",
    "  yhat=tunnedModel.predict(X_test)\n",
    "  yhatTrain=tunnedModel.predict(X_train)\n",
    "  mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "  mse = metrics.mean_squared_error(y_test, yhat)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = metrics.r2_score(y_test,yhat)\n",
    "  print('>stackedDE %.3f,%.3f,%.3f,%.3f' % (mae,mse,rmse,r2))\n",
    "  \n",
    "  return mae,mse,rmse,r2,yhat,tunnedModel,yhatTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "a_LsZayCKYwf",
    "outputId": "82d3a55f-0471-482a-8e18-d5762852d4f4"
   },
   "outputs": [],
   "source": [
    "stackedName='stacking_SVM'\n",
    "metamodel=SVR(kernel='rbf')\n",
    "\n",
    "selectedModels=dict()\n",
    "selectedModels['SVR']= models['SVR']\n",
    "# selectedModels['kNN']=   models['kNN'] \n",
    "selectedModels['XGBoost']=   models['XGBoost'] \n",
    "maeE,mseE,rmseE,r2E,yhatE,tunnedModelE,yHatTrainE=runStackedEnsemble(selectedModels,X_train,y_train,y_test,stackedName,metamodel)\n",
    "\n",
    "\n",
    "# selectedModelsUCS1=dict()\n",
    "# # selectedModelsUCS1['XGB']= modelsyUCS['XGB']\n",
    "# selectedModelsUCS1['MLP']= modelsyUCS['MLP'] \n",
    "# # selectedModelsUCS1['SVR']= modelsyUCS['SVR'] \n",
    "# selectedModelsUCS1['RF']= modelsyUCS['RF']\n",
    "# selectedModelsUCS1['kNN']= modelsyUCS['kNN']\n",
    "# print('model1')\n",
    "# maeUCS1,mseUCS1,rmseUCS1,r2UCS1,yhatUCS1,tunnedModelUCS1=runStackedEnsemble(selectedModelsUCS1,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "Hb6lTW7YedMj",
    "outputId": "97e16f9c-3ec5-4845-d732-c8a3a5949df3"
   },
   "outputs": [],
   "source": [
    "print(maeE,mseE,rmseE,r2E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpJGEoNa9BzZ",
    "outputId": "b502e315-002b-43f4-c243-203e1b27ebc3"
   },
   "outputs": [],
   "source": [
    "print(tunnedModelE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQeEw_EIIDEh"
   },
   "outputs": [],
   "source": [
    "# selectedModelsUCS2=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName='stacking_MLP'\n",
    "# metamodel=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCS2['MLP']= modelsyUCS['MLP'] \n",
    "# selectedModelsUCS2['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('model2')\n",
    "# maeUCS2,mseUCS2,rmseUCS2,r2UCS2,yhatUCS2,tunnedModelUCS2,yHatTrainUCS=runStackedEnsemble(selectedModelsUCS2,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "# print(maeUCS2,mseUCS2,rmseUCS2,r2UCS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_D9Jiq5gZOOx"
   },
   "outputs": [],
   "source": [
    "# print(maeUCS2,mseUCS2,rmseUCS2,r2UCS2)\n",
    "# print(tunnedModelUCS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kh40zm2fBAoi"
   },
   "outputs": [],
   "source": [
    "# selectedModelsUCSTrain=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName='stacking_MLP'\n",
    "# metamodel=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCSTrain['MLP']= modelsyUCS['MLP'] \n",
    "# selectedModelsUCSTrain['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('modelUCS_based on Training Data')\n",
    "# maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain,yhatUCS_basedOnTrain,tunnedModelUCS_basedOnTrain,yHatTrainUCS_basedOnTrain=runStackedEnsemble(selectedModelsUCSTrain,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "# print(maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "tAa6LkK7dYcb",
    "outputId": "c5882c8c-dd5c-4057-af87-f99c7a28f7f8"
   },
   "outputs": [],
   "source": [
    "selectedModelsUCS3Train=dict()\n",
    "# selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "stackedName3='stacking_MLP'\n",
    "metamodel3=MLPRegressor(max_iter=4000, random_state=1)\n",
    "selectedModelsUCS3Train['RF']= modelsyUCS['RF'] \n",
    "selectedModelsUCS3Train['MLP']= modelsyUCS['MLP'] \n",
    "print('modelUCS_based on Training Data')\n",
    "maeUCS3,mseUCS3,rmseUCS3,r2UCS3,yhatUCS3,tunnedModelUCS3,yHatTrainUCS3=runStackedEnsemble(selectedModelsUCS3Train,X_train,y_trainyUCS,y_testyUCS,stackedName3,metamodel3)\n",
    "print(maeUCS3,mseUCS3,rmseUCS3,r2UCS3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8sDfJxe4q4k",
    "outputId": "2014fafd-c578-4418-fded-88c93730ec1b"
   },
   "outputs": [],
   "source": [
    "print(tunnedModelUCS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLb9LHgGRq2L"
   },
   "outputs": [],
   "source": [
    "# selectedModelsUCS4Train=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName4='stacking_SVM'\n",
    "# # stackedName='stacking_SVM'\n",
    "# metamodel4=SVR(kernel='rbf')\n",
    "\n",
    "# # metamodel4=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCS4Train['SVR']= modelsyUCS['SVR'] \n",
    "# selectedModelsUCS4Train['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('modelUCS_based on Training Data')\n",
    "# maeUCS4_basedOnTrain,mseUCS4_basedOnTrain,rmseUCS4_basedOnTrain,r2UCS4_basedOnTrain,yhatUCS4_basedOnTrain,tunnedModelUCS4_basedOnTrain,yHatTrainUCS4_basedOnTrain=runStackedEnsemble(selectedModelsUCS4Train,X_train,y_trainyUCS,y_testyUCS,stackedName4,metamodel4)\n",
    "# print(maeUCS4_basedOnTrain,mseUCS4_basedOnTrain,rmseUCS4_basedOnTrain,r2UCS4_basedOnTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuMAlaArqUMx"
   },
   "outputs": [],
   "source": [
    "# print(maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvdYtvJbPbBe"
   },
   "outputs": [],
   "source": [
    "  # tunnedModel=get_bestParm('stacking_SVM',stackModel ,X_train,y_train.ravel(),[])\n",
    "  # tunnedModel=get_bestParm('stacking_DNN',stackModel ,X_train,y_train.ravel())\n",
    "  # tunnedModel=stackModel\n",
    "  # print(tunnedModel)\n",
    "  # metamodel=SVR(kernel='rbf',C=0.7977,gamma= 0.0841)\n",
    "  # modelm = get_stacking(selectedModels,metamodel)\n",
    "  # print(modelm)\n",
    "  # print('----')\n",
    "  # print(stackModel)\n",
    "  # mae[name],mse[name],rmse[name],r2[name] = evaluate_model(tunnedModel,X_train, X_test, y_train.ravel(), y_test.ravel())\n",
    "  # print(tunnedModel)\n",
    "  # tunnedModel.fit(X_train,y_train.ravel())\n",
    "  # yhat=tunnedModel.predict(X_test)\n",
    "  # mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "  # mse = metrics.mean_squared_error(y_test, yhat)\n",
    "  # rmse = np.sqrt(mse)\n",
    "  # r2 = metrics.r2_score(y_test,yhat)\n",
    "  # print('Coefficient: %.1f',coefficient)\n",
    "  # print('>stackedDE %.3f,%.3f,%.3f,%.3f' % (mae,mse,rmse,r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lTsuyca83FX3",
    "outputId": "c246bc76-3ceb-48d9-b55e-fb2214ff36c9"
   },
   "outputs": [],
   "source": [
    "# print(r2)\n",
    "yhatUCS2=yhatUCS3\n",
    "r2UCS2=r2UCS3\n",
    "\n",
    "i=0\n",
    "for name in models.keys():\n",
    "  plotScatter(y_test,predictedY[i,:],'E',name,r2[name],[0,1])\n",
    "  i=i+1\n",
    "plotScatter(y_test,yhatE,'E','Stacking Ensemble',r2E,[0,1])\n",
    "\n",
    "i=0\n",
    "for name in modelsyUCS.keys():\n",
    "  plotScatter(y_testyUCS,predictedyUCS[i,:],'UCS',name,r2yUCS[name],[1,3])\n",
    "  i=i+1\n",
    "plotScatter(y_testyUCS,yhatUCS2,'UCS','Stacking Ensemble',r2UCS2,[1,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WU8praak-Np_"
   },
   "outputs": [],
   "source": [
    "print('>sorted Results in R2')\n",
    "{k: v for k, v in sorted(r2.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "073aePIAVgDh"
   },
   "outputs": [],
   "source": [
    "def plotPredictedValues(predictedY,actualY,yLabel,models,predictedYStacked):\n",
    "  \n",
    "  _, ax = plt.subplots()\n",
    "  ax.set_frame_on(True)\n",
    "  ax.tick_params(direction='out')\n",
    "  ax.set_facecolor(\"white\")\n",
    "  ax.set_axis_on()\n",
    "  # plt.rcParams[\"legend.loc\"] = 'best'\n",
    "  plt.rcParams['axes.unicode_minus'] = False\n",
    "  plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "  plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "  plt.grid(False)\n",
    "  xValues=np.array(range(1,len(actualY)+1))\n",
    "  i=0\n",
    "  for name in models.keys():\n",
    "    plt.plot(xValues,predictedY[i,:], '^', label= name)\n",
    "    i=i+1\n",
    "  plt.plot(xValues,predictedYStacked, 'o', label= 'Stacking Ensemble')\n",
    "  plt.plot(xValues,actualY, 'k-', label= 'Observed')\n",
    "  xi = list(range(1,len(xValues)+1))\n",
    "  print('----')\n",
    "  print(xi)\n",
    "  print(xValues)\n",
    "  # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%this line is needed for test data \n",
    "  if len(actualY)<20:\n",
    "    plt.xticks(xi,xValues)\n",
    "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "      fancybox=True, shadow=True, ncol=2, prop={'family': 'Times New Roman Cyr'}, fontsize=14)\n",
    "  ax.set_frame_on(True)\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "  box = ax.get_position()\n",
    "  ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "  ax.set_xlabel('Data Points', fontsize=14 , fontweight='normal')\n",
    "  ax.set_ylabel( yLabel, fontsize=14 , fontweight='normal')\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "id": "TjA3jEaipB6z",
    "outputId": "a502c6d9-e48b-4499-ee76-2a5dd4add455"
   },
   "outputs": [],
   "source": [
    "plotPredictedValues(predictedY,y_test,'E (GPa)',models,yhatE)\n",
    "# print(predictedY)\n",
    "\n",
    "plotPredictedValues(predictedyUCS,y_testyUCS,'UCS (MPa)',modelsyUCS,yhatUCS3)\n",
    "# print(predictedyUCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "8J657V0h9E6e",
    "outputId": "169a69d3-0b07-4bbc-d66d-e3ac5fcf83e1"
   },
   "outputs": [],
   "source": [
    "plotPredictedValues(PredictedYTrain,y_train,'E (GPa)',models,yHatTrainE)\n",
    "# print(predictedY)\n",
    "\n",
    "yHatTrainUCS=yHatTrainUCS3\n",
    "plotPredictedValues(PredictedYTrainUCS,y_trainyUCS,'UCS (MPa)',modelsyUCS,yHatTrainUCS)\n",
    "# print(predictedyUCS)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
