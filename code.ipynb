{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9061054",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msn\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisartist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxislines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Subplot\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# from keras.models import Sequential \u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# from keras.layers import Dense\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# import tensorflow as tf\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# from keras import backend as K\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# from keras.wrappers.scikit_learn import KerasRegressor\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn_evaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n",
    "\n",
    "def index_of_agreement(predicted, observed):\n",
    "    \"\"\"Calculates the Index of Agreement (IOA) between predicted and observed values.\"\"\"\n",
    "    n = len(predicted)\n",
    "    mean_observed = sum(observed) / n\n",
    "    \n",
    "#     numerator = sum((predicted[i] - observed[i]) ** 2 for i in range(n))\n",
    "    numerator = sum((predicted[i] - observed[i]) for i in range(n))\n",
    "#     denominator = sum((abs(predicted[i] - mean_observed) + abs(observed[i] - mean_observed)) ** 2 for i in range(n))\n",
    "    denominator = sum((observed[i] - mean_observed) for i in range(n))\n",
    "    \n",
    "    ioa = 1 - (numerator / denominator)\n",
    "    return ioa\n",
    "\n",
    "def weighted_mean_absolute_percentage_error(predicted, observed):\n",
    "    \"\"\"Calculates the Weighted Mean Absolute Percentage Error (WMAPE) between predicted and observed values.\"\"\"\n",
    "    n = len(predicted)\n",
    "    numerator = sum(observed[i] * abs((predicted[i] - observed[i])/observed[i]) for i in range(n))\n",
    "    denominator = sum(observed[i] for i in range(n))\n",
    "    wmape = numerator / denominator\n",
    "    return wmape\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# pip install sklearn-evaluation\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "\n",
    "# drive.mount\n",
    "# uploaded = files.upload()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# remained Works:  parameter tunning of initial Estimators of meta model, selection of final estimator,plot results of grid search, XGBoost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# compare ensemble to each standalone models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "# from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from numpy import where\n",
    "from scipy import stats\n",
    "import seaborn as sn\n",
    "from mpl_toolkits.axisartist.axislines import Subplot\n",
    "from xgboost import XGBRegressor\n",
    "# from keras.models import Sequential \n",
    "# from keras.layers import Dense\n",
    "# import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn_evaluation import plot\n",
    "\n",
    "from permetrics.regression import RegressionMetric\n",
    "\n",
    "# import scikeras\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "# Edf=pd.read_csv(\"E.csv\")\n",
    "# UCSdf=pd.read_csv(\"UCS.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    print('get_dataset function is running...')\n",
    "\n",
    "    import io\n",
    "    df =pd.read_csv(\"E.csv\")\n",
    "    # df =pd.read_csv('E:/MyPapers/Dr Freidooni2/data/E.csv')\n",
    "    # dfUCS =pd.read_csv('E:/MyPapers/Dr Freidooni2/data/UCS.csv')\n",
    "    dfUCS =pd.read_csv(\"UCS.csv\")\n",
    "    # df = pd.read_excel (io.BytesIO(uploaded['E.csv'])) #place \"r\" before the path string to address special character, such as '\\'. Don't forget to put the file name at the end of the path + '.xlsx'\n",
    "    y=df['E']\n",
    "    yUCS=dfUCS['UCS']\n",
    "    X=df[['d','ne','vp','HBN']]\n",
    "#     print(X)\n",
    "    return X,y,yUCS\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# import pandas as pd \n",
    "# print(uploaded['E.csv'])\n",
    "\n",
    "X, y,yUCS = get_dataset()\n",
    "# import tensorflow as tf\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# !wget \"https://dl.freefontsfamily.com/download/Times-New-Roman.zip\"\n",
    "# !unzip \"download?family=Times-New-Roman\"\n",
    "# uploaded = files.upload()\n",
    "# from IPython import get_ipython\n",
    "# get_ipython().system('mv times_new_roman.ttf /usr/share/fonts/truetype/')\n",
    "\n",
    "# get_ipython().system('fc-cache -f -v')\n",
    "\n",
    "# from matplotlib import font_manager\n",
    "import matplotlib.font_manager\n",
    "font_files =matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "\n",
    "\n",
    "# font_dirs = ['C:/Windows/Fonts/']\n",
    "# font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    matplotlib.font_manager.fontManager.addfont(font_file)\n",
    "\n",
    "# fm = font_manager.font_manager\n",
    "# fm.get_cachedir()\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "[f.name for f in matplotlib.font_manager.fontManager.ttflist]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "# # set font\n",
    "plt.rcParams['font.family'] = 'Times New Roman Cyr'\n",
    "plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "\n",
    "# drive.mount('mntdrive/')\n",
    "Features = np.array([\"$\\gamma_d(kN/m^3)$\",\"$n_e$(%)\",\"$v_p$(m/s)\",\"HBN(kgf/$mm^2$)\"])\n",
    "# from google.colab import drive\n",
    "# drive.mount('/Figures')\n",
    "images_dir = '/'\n",
    "# y = np.array([3, 8, 1, 10])\n",
    "# print(type(X))\n",
    "XMatrix=X.to_numpy()\n",
    "type(y)\n",
    "type(yUCS)\n",
    "\n",
    "for i in range(4):\n",
    "  plt.hist(XMatrix[:,i].transpose(), bins = 7,density=True, color='b',  edgecolor='black')\n",
    "  plt.rc('font', size=16)          # controls default text sizes\n",
    "  plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "  plt.rc('ytick', labelsize=14)\n",
    "  plt.xlabel(Features[i])\n",
    "  plt.ylabel('Frequency')\n",
    "  mu, std = norm.fit(XMatrix[:,i])\n",
    "  # Plot the PDF.\n",
    "  xmin, xmax = plt.xlim()\n",
    "  x = np.linspace(xmin, xmax, 100)\n",
    "  # print(x)\n",
    "  p = norm.pdf(x, mu, std)\n",
    "  # print(p)\n",
    "  plt.plot(x, p, 'r', linewidth=2)\n",
    "  title = \"Mean = {:.2f}, Std Dev= {:.2f}, N=70\".format(mu, std)\n",
    "  plt.title(title)\n",
    "  \n",
    "  plt.show() \n",
    "  plt.savefig(f\"{images_dir}testFigure.jpg\")\n",
    "  # plt.savefig('Histogram.jpg')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Features = np.array([\"E (GPa)\",\"UCS (MPa)\"])\n",
    "Features = np.array([\"UCS (MPa)\"])\n",
    "print(type(yUCS))\n",
    "yEArray=np.array(y)\n",
    "yUCSArray=np.array(yUCS)\n",
    "# y=np.concatenate((yEArray,yUCSArray),axis=0)\n",
    "# yMatrix=yEArray\n",
    "yMatrix=yUCSArray\n",
    "for i in range(1):\n",
    "  plt.hist(yMatrix.transpose(), bins = 7,density=True, color='b',  edgecolor='black')\n",
    "  plt.rc('font', size=16)          # controls default text sizes\n",
    "  plt.rc('xtick', labelsize=14)    # fontsize of the tick labels\n",
    "  plt.rc('ytick', labelsize=14)\n",
    "  plt.xlabel(Features[i])\n",
    "  plt.ylabel('Frequency')\n",
    "  mu, std = norm.fit(yMatrix)\n",
    "  # Plot the PDF.\n",
    "  xmin, xmax = plt.xlim()\n",
    "  x = np.linspace(xmin, xmax, 100)\n",
    "  # print(x)\n",
    "  p = norm.pdf(x, mu, std)\n",
    "  # print(p)\n",
    "  plt.plot(x, p, 'r', linewidth=2)\n",
    "  title = \"Mean = {:.2f}, Std Dev= {:.2f}, N=70\".format(mu, std)\n",
    "  plt.title(title)\n",
    "\n",
    "plt.show() \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "      print(\"coeff_determination function is running...\")\n",
    "\n",
    "      SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "      SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "      return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "# from sensitivity import sensitivityAnalysis\n",
    "# sensitivityValues={'d':[2.17,8.03],'ne':[22.01,25.78],'vp':[3759.79,5347.06],'HBN':[271.81,975.79]}\n",
    "# sa=sensitivityAnalysier(sensitivityValues,X)\n",
    "# sa.df\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# my function: find best parameters by grid search\n",
    "def get_bestParm(name,model,X,y,weights):\n",
    "    print(\"get_bestParm function is running....\")\n",
    "\n",
    "    foldCount=3;\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     single metric\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "    refitValue=\"neg_mean_squared_error\"\n",
    "#     scoring = \"r2\"\n",
    "#     refitValue=True\n",
    "    if name=='SVR':\n",
    "        params={\n",
    "            \"gamma\": [0.001,0.01,0.1,1,10],\n",
    "                \"C\": [0.001,0.01,0.1,1,10,100],\n",
    "                \"epsilon\":[0.001,0.01,0.1,1,10]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params,scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        parmsNames=['$\\gamma$','C','$\\epsilon$']\n",
    "        plot_search_results(grid_search,parmsNames)\n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_, execution_time\n",
    "    elif name=='cart':\n",
    "        params={'splitter':('best','random'),\n",
    "            'max_depth' : [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "           'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10],\n",
    "           'min_weight_fraction_leaf':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           'max_features':('auto','log2','sqrt',None),\n",
    "           'max_leaf_nodes':[None,10,20,30,40,50,60,70,80,90] }\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                         scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        return grid_search.best_estimator_, execution_time\n",
    "    elif name=='kNN':\n",
    "        params={'n_neighbors':[2,4,6,8,10,12,14,16,18,20],'weights':['uniform','distance']}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                           scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "#         grid_search.fit(X,y)\n",
    "        if \"r2\" in scoring:\n",
    "            plot_grid_search(grid_search,\n",
    "                                 'r2',\n",
    "                                 params['n_neighbors'], \n",
    "                                 params['weights'],\n",
    "                                 'k',\n",
    "                                 'weights',[10,2])\n",
    "        if \"neg_mean_squared_error\" in scoring:\n",
    "            plot_grid_search(grid_search,\n",
    "                                 'neg_mean_squared_error',\n",
    "                                 params['n_neighbors'], \n",
    "                                 params['weights'],\n",
    "                                 'k',\n",
    "                                 'weights',[10,2])\n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='RF':\n",
    "        params={'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    "                'n_estimators':[200,300,400,500]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "#         grid_search.fit(X,y)\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        legendLabel=['Estimatior#: 200', 'Estimatior#: 300', 'Estimatior#: 400', 'Estimatior#: 500']\n",
    "        newPlot_grid_search(grid_search,\n",
    "                                 'neg_mean_squared_error',\n",
    "                                 params['max_depth'], \n",
    "                                 params['n_estimators'],\n",
    "                                ['max_depth','n_estimators'],\n",
    "                                 'Maximum tree depth',\n",
    "                                 'Estimators#',[11,10],legendLabel)\n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='MLP':\n",
    "        params={\n",
    "            'solver' : ['lbfgs',  'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "            (7,),(8,),(9,),(10,),(11,),(12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,)\n",
    "             ]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "#         grid_search.fit(X,y)\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        legendLabel=['Solver: Adam', 'Solver: L-BFGS']\n",
    "        newPlot_grid_search(grid_search,\n",
    "                             'neg_mean_squared_error',\n",
    "                               [7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "                                        ['L-BFGS','Adam'],['hidden_layer_sizes','solver'],\n",
    "                             'Hidden Layer Sizes',\n",
    "                                 'Solver',[3,11],legendLabel)\n",
    "        \n",
    "        print(\"{{{{{{}}}}}}\")\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "        print(grid_search.best_estimator_)\n",
    "        return grid_search.best_estimator_\n",
    "    elif name=='MLP2':\n",
    "            params={\n",
    "                'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "                'hidden_layer_sizes': [\n",
    "                 (1,2),(2,2),(3,2),(4,2),(5,2),(6,2),(7,2),(8,2),(9,2),(10,2),\n",
    "                    (1,3),(2,3),(3,3),(4,3),(5,3),(6,3),(7,3),(8,3),(9,3),(10,3),\n",
    "                    (1,4),(2,4),(3,4),(4,4),(5,4),(6,4),(7,4),(8,4),(9,4),(10,4),\n",
    "                    (1,5),(2,5),(3,5),(4,5),(5,5),(6,5),(7,5),(8,5),(9,5),(10,5)\n",
    "                 ]}\n",
    "            grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                              scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "#             grid_search.fit(X,y)\n",
    "            start_time = time.time()\n",
    "            grid_search.fit(X,y)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            if \"r2\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                     'r2',\n",
    "                                     params['hidden_layer_sizes'], \n",
    "                                     params['solver'],\n",
    "                                     'Hidden Layer Sizes',\n",
    "                                     'Solver')\n",
    "            plot_grid_search(grid_search,\n",
    "                                 'neg_mean_squared_error',\n",
    "                                 params['hidden_layer_sizes'], \n",
    "                                 params['solver'],\n",
    "                                 'hidden_layer_sizes',\n",
    "                                 'solver')\n",
    "            print(\"{{{{{{}}}}}}\")\n",
    "            print(grid_search.best_estimator_)\n",
    "            return grid_search.best_estimator_, execution_time\n",
    "    elif name=='XGBoost':\n",
    "            params={\n",
    "                'n_estimators' : [400,600,800,1000, 1200,1400,1600,1800, 2000],\n",
    "                'max_depth': [5,10, 20,30,40,50, 60, 70, 80, 90, 100],\n",
    "            'learning_rate':[0.01, 0.1, 0.2, 0.3,0.4, 0.5,0.6,0.7,0.8,0.9]}\n",
    "            grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                              scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "            start_time = time.time()\n",
    "            grid_search.fit(X,y)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            parmsNames=['Estimators#','Maximum tree depth','Learning rate']\n",
    "            plot_search_results(grid_search, parmsNames)\n",
    "            print(\"{{{{{{}}}}}}\")\n",
    "            print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "            print('the std of best score of {0} ={1}'.format(name,grid_search.cv_results_['std_test_score'][grid_search.best_index_]))\n",
    "            print(grid_search.best_estimator_)\n",
    "            return grid_search.best_estimator_\n",
    "\n",
    "    elif name=='stacking':\n",
    "        start_time = time.time()\n",
    "        model.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        return model, execution_time\n",
    "    elif name=='stacking_SVM':\n",
    "\n",
    "        params={\n",
    "            'final_estimator__gamma':[0.001,0.01,0.1,1,10,100],\n",
    "            'final_estimator__C': [ 0.001,0.01,0.1,1,10],\n",
    "            'final_estimator__epsilon':[0.001,0.01,0.1,1,10],\n",
    "        }\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "        \n",
    "        parmsNames=['$\\gamma$','C','$\\epsilon$']\n",
    "#         grid_search.fit(X,y)\n",
    "        start_time = time.time()\n",
    "        model.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        plot_search_results(grid_search,parmsNames)\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        return grid_search.best_estimator_ \n",
    "    elif name=='stacking_XGB':\n",
    "        print('model:')\n",
    "        print(model)\n",
    "        print('parms:')\n",
    "        print(model.get_params().keys())\n",
    "        params={\n",
    "            'final_estimator__n_estimators' : [400,600,800,1000, 1200,1400,1600,1800, 2000],\n",
    "            'final_estimator__max_depth': [5,10, 20,30,40,50, 60, 70, 80, 90, 100],\n",
    "            'final_estimator__learning_rate':[0.01, 0.1, 0.2, 0.3,0.4, 0.5,0.6,0.7,0.8,0.9]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "#         grid_search.fit(X,y)\n",
    "        start_time = time.time()\n",
    "        model.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        if len(params)<=2:\n",
    "            if \"r2\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                     'r2',\n",
    "                                     params['final_estimator__n_estimators'], \n",
    "                                     params['final_estimator__learning_rate'],\n",
    "                                     'Estimators#',\n",
    "                                     'Learning Rate',[9,10,11])\n",
    "            if \"neg_mean_squared_error\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                     'neg_mean_squared_error',\n",
    "                                     params['final_estimator__n_estimators'], \n",
    "                                     params['final_estimator__learning_rate'],\n",
    "                                     'Estimators#',\n",
    "                                     'Learning Rate',[9,10,11])\n",
    "        return grid_search.best_estimator_, execution_time\n",
    "    elif name=='stacked_XGB':\n",
    "        params={\n",
    "            'final_estimator__n_estimators' : [400,800, 1200,1600, 2000],\n",
    "            'final_estimator__max_depth': [5,10, 20,40, 60,  80,  100],\n",
    "        'final_estimator__learning_rate':[0.01,  0.2, 0.4, 0.6,0.8]}\n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3)\n",
    "#         grid_search.fit(X,y)\n",
    "        start_time = time.time()\n",
    "        model.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        if len(params)<=2:\n",
    "            if \"r2\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                  'r2',\n",
    "                                  params['n_estimators'], \n",
    "                                  params['max_depth'],\n",
    "                                  'Estimators#',\n",
    "                                  'Max Depth',\n",
    "                                 [5,7,5])\n",
    "            if \"neg_mean_squared_error\" in scoring:\n",
    "                plot_grid_search(grid_search,\n",
    "                                  'neg_mean_squared_error',\n",
    "                                  params['n_estimators'], \n",
    "                                  params['max_depth'],\n",
    "                                  'Estimators#',\n",
    "                                  'Max Depth',[5,7,5])\n",
    "        return grid_search.best_estimator_, execution_time\n",
    "    elif name=='stacking_MLP':\n",
    "\n",
    "        params={\n",
    "            'final_estimator__solver' : ['lbfgs', 'adam'],\n",
    "            'final_estimator__hidden_layer_sizes': [               \n",
    "            #  (1,),(2,),(3,),(4,),(5,),(6,),\n",
    "            (7,),(8,),(9,),(10,),(11,),(12,),(13,),(14,),(15,),(16,),(17,),(18,),(19,),(20,)\n",
    "             ]}      \n",
    "        grid_search = GridSearchCV(estimator = model, param_grid = params, \n",
    "                          scoring=scoring,refit=True,return_train_score=True,cv = foldCount, n_jobs = -1, verbose = 3, )      \n",
    "#         grid_search.fit(X,y)\n",
    "        start_time = time.time()\n",
    "        model.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        legendLabel=[ 'Solver: L-BFGS','Solver: Adam']\n",
    "        newPlot_grid_search(grid_search,\n",
    "                             'neg_mean_squared_error',\n",
    "                               [7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n",
    "                                        ['L-BFGS','Adam'],['final_estimator__hidden_layer_sizes','final_estimator__solver'],\n",
    "                            'Hidden Layer Sizes','Solver',[20,20],legendLabel)\n",
    "        print('the best score of {0} ={1}'.format(name,grid_search.best_score_) )\n",
    "        return grid_search.best_estimator_  , execution_time\n",
    "    else:   \n",
    "        start_time = time.time()\n",
    "        model.fit(X,y)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        return model,execution_time\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def plot_search_results(grid, parmNames):\n",
    "    print(\"plot_search_results function is running...\")\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Params: \n",
    "        grid: A trained GridSearchCV object.\n",
    "        parmNames: parmameter names for displaying in Figure\n",
    "    \"\"\"\n",
    "    ## Results from grid search\n",
    "    results = grid.cv_results_\n",
    "    means_test = results['mean_test_score']\n",
    "    stds_test = results['std_test_score']\n",
    "    # means_train = results['mean_train_score']\n",
    "    # stds_train = results['std_train_score']\n",
    "\n",
    "    ## Getting indexes of values per hyper-parameter\n",
    "    masks=[]\n",
    "    masks_names= list(grid.best_params_.keys())\n",
    "    # masks_names=parmNames\n",
    "    for p_k, p_v in grid.best_params_.items():\n",
    "        masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "    params=grid.param_grid\n",
    "\n",
    "    ## Ploting results\n",
    "    fig, ax = plt.subplots(1,len(params),sharex='none', sharey='all',figsize=(20,5))\n",
    "    # fig.suptitle('Score per parameter')\n",
    "    fig.text(0.04, 0.5, 'Negative MSE', va='center', rotation='vertical')\n",
    "    fig.text(0.04, 0.5, 'Negative MSE', va='center', rotation='vertical')\n",
    "    pram_preformace_in_best = {}\n",
    "    for i, p in enumerate(masks_names):\n",
    "        m = np.stack(masks[:i] + masks[i+1:])\n",
    "        pram_preformace_in_best\n",
    "        best_parms_mask = m.all(axis=0)\n",
    "        best_index = np.where(best_parms_mask)[0]\n",
    "        x = np.array(params[p])\n",
    "        y_1 = np.array(means_test[best_index])\n",
    "        e_1 = np.array(stds_test[best_index])\n",
    "        # y_2 = np.array(means_train[best_index])\n",
    "        # e_2 = np.array(stds_train[best_index])\n",
    "        ax[i].errorbar(x, y_1, e_1, linestyle='-', marker='o', label='test')\n",
    "        # ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "        # ax[i].set_xlabel(p.upper())\n",
    "        ax[i].set_xlabel(parmNames[i])\n",
    "\n",
    "    # plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def newPlot_grid_search(grid_search, metric, grid_param_1, grid_param_2, originalParmNames,name_param_1, name_param_2,ColumnsCount,legendLabel):\n",
    "    print(\"newPlot_grid_search function is running...\")\n",
    "    \n",
    "    cv_results=grid_search.cv_results_\n",
    "    _, ax = plt.subplots()\n",
    "    ax.set_frame_on(True)\n",
    "    ax.tick_params(direction='out')\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.set_axis_on()\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "    plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "    plt.grid(False)\n",
    "    coefficient=-1\n",
    "    metricLabel='Negative MSE'\n",
    "    if metric=='r2':    \n",
    "      coefficient=1 \n",
    "      metricLabel=\"$R^2$\" \n",
    "    ax.set_frame_on(True)\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "\n",
    "\n",
    "    print('originalParmNames[0]={0}'.format(originalParmNames[0]))\n",
    "    print('gridParm1={0}'.format(grid_param_1))\n",
    "    print('name_param_1={0}'.format(name_param_1))\n",
    "\n",
    "   # ax=plot.grid_search(grid_search.cv_results_, (originalParmNames[0]),None,'line',None,ax)\n",
    "    #ax.set_xticklabels(grid_param_1)\n",
    "    # ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "    #       fancybox=True, shadow=True, ncol=np.min([ColumnsCount[0],2]), prop={'family': 'Times New Roman Cyr'}, fontsize=14,labels=legendLabel)\n",
    "    \n",
    "    # ax.set_xlabel(name_param_1, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    # plt.xlabel(name_param_1)\n",
    "    \n",
    "    # ax.set_ylabel( metricLabel, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    # plt.title('')\n",
    "    # plt.show()    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def plot_grid_search(grid_search, metric, grid_param_1, grid_param_2, name_param_1, name_param_2,ColumnsCount):\n",
    "    print(\"plot_grid_search function is running...\")\n",
    "    \n",
    "    # print(grid_search.grid_scores_)\n",
    "    cv_results=grid_search.cv_results_\n",
    "    # print(cv_results)\n",
    "    # Get Test Scores Mean and std for each grid search\n",
    "    # scores_mean = cv_results[('mean_test_' + metric)]\n",
    "    # scores_sd = cv_results[('std_test_' + metric)]\n",
    "    scores_mean = cv_results['mean_test_score']\n",
    "    print('cv_results.best_score_={0}'.format(grid_search.best_score_))\n",
    "    print('cv_results.best_params_={0}'.format(grid_search.best_params_))\n",
    "    print('cv_results[mean_test_score]={0}'.format( cv_results['mean_test_score']))\n",
    "    print('cv_results[mean_train_score]={0}'.format( cv_results['mean_train_score']))\n",
    "    cv_resultsDf = pd.DataFrame.from_dict(grid_search.cv_results_)\n",
    "    print('data frame ='.format(cv_resultsDf))\n",
    "    scores_df=pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    print('best row'.format(best_row['mean_test_score']))\n",
    "    scores_sd = cv_results['std_test_score']\n",
    "    print(pd.DataFrame(cv_results).loc[:, ['mean_test_score', 'rank_test_score']].sort_values(by='rank_test_score'))    \n",
    "\n",
    "    if grid_param_2 is not None:\n",
    "        scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "        scores_sd = np.array(scores_sd).reshape(len(grid_param_2),len(grid_param_1))\n",
    "    print('scores_mean:')\n",
    "    print(scores_mean)\n",
    "    # Set plot style\n",
    "#     plt.style.use('seaborn')\n",
    "    \n",
    "#     plt.rcParams['axes.edgecolor'] = 'black'\n",
    "    # Plot Grid search scores\n",
    "    _, ax = plt.subplots()\n",
    "    ax.set_frame_on(True)\n",
    "    ax.tick_params(direction='out')\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.set_axis_on()\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "    plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "    plt.grid(False)\n",
    "    coefficient=-1\n",
    "    metricLabel='MSE'\n",
    "    if metric=='r2':    \n",
    "      coefficient=1 \n",
    "      metricLabel=\"$R^2$\" \n",
    "    if grid_param_2 is not None:\n",
    "        # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "        for idx, val in enumerate(grid_param_2):\n",
    "            ax.plot(grid_param_1,coefficient*scores_mean[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "          fancybox=True, shadow=True, ncol=np.min([ColumnsCount[1],2]), prop={'family': 'Times New Roman Cyr'}, fontsize=14)\n",
    "    else:\n",
    "        # If only one Param1 is given\n",
    "        ax.plot(grid_param_1, coefficient*scores_mean, '-o',label=name_param_1)\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "          fancybox=True, shadow=True, ncol=np.min([ColumnsCount[0],3]), prop={'family': 'Times New Roman Cyr'}, fontsize=14)\n",
    "\n",
    "    # only for MLP\n",
    "    if name_param_1=='Hidden Layer Sizes':\n",
    "      plt.xticks(grid_param_1)\n",
    "\n",
    "    ax.set_frame_on(True)\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "    ax.set_xlabel(name_param_1, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    \n",
    "    # ax.set_ylabel('CV ' + str.capitalize(metric), fontsize=16 , fontweight='normal')\n",
    "    ax.set_ylabel( metricLabel, fontsize=14 , fontweight='normal', fontFamily='Times New Roman Cyr')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    print(\"get_models function is running...\")\n",
    "\n",
    "    seed = np.random.seed(22)\n",
    "    rng = np.random.RandomState(1)\n",
    "    models = dict()\n",
    "    models['XGBoost'] = XGBRegressor()\n",
    "    # models['kNN'] = KNeighborsRegressor()   \n",
    "    models['MLP'] = MLPRegressor(max_iter=2000, random_state=1)\n",
    "    models['SVR'] = SVR(kernel='rbf' )\n",
    "    models['RF'] = RandomForestRegressor(random_state=rng)\n",
    "\n",
    "    #  models['LR'] = LinearRegression()\n",
    "    # models['MLP2'] = MLPRegressor(max_iter=2000, random_state=1)\n",
    "    # models['cart'] = DecisionTreeRegressor()\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import tensorflow as tf\n",
    "\n",
    "    from keras import backend as K\n",
    "\n",
    "    def coeff_determination(y_true, y_pred):\n",
    "      print(\"coeff_determination is running...\")\n",
    "\n",
    "      SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "      SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "      return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[coeff_determination])\n",
    "\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model,X_train, X_test, y_train, y_test):\n",
    "    print(\"evaluate_model function is running...\")\n",
    "\n",
    "    history=model.fit(X_train,y_train)\n",
    "    yhatTrain=model.predict(X_train)\n",
    "    yhat=model.predict(X_test)\n",
    "    mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "    mse = metrics.mean_squared_error(y_test, yhat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_test,yhat)\n",
    "    evaluator=RegressionMetric(y_test, yhat)\n",
    "    # results=evaluator.get_metrics_by_list_names(list_metric_names=[\"RMSE\",\"VAF\",\"MAPE\",\"A20\",\"CI\"],list_paras=[{\"multi_output\":\"raw_values\"},]*5)\n",
    "    # VAF=evaluator.VAF(multi_output=\"raw_values\")\n",
    "    return yhat,mae,mse,rmse,r2,history,yhatTrain, evaluator\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "dim=4\n",
    "arrayX=X.to_numpy()\n",
    "arrayY=y.to_numpy()\n",
    "arrayyUCS=yUCS.to_numpy()\n",
    "# Sensitivity Analysis\n",
    "rr=[0,0,0,0]\n",
    "for j in range(dim):\n",
    "  temp=arrayX[:,j]*arrayY[:]\n",
    "  temp1=np.power(arrayX[:,j],2)\n",
    "  temp2=np.power(arrayY,2)\n",
    "  rr[j]=(np.sum(temp)/np.sqrt(np.sum(temp1)*np.sum(temp2)))\n",
    "  \n",
    "# print(rr)\n",
    "\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "c = ['red', 'green', 'orange', 'blue']\n",
    "# ax.bar(['$\\gamma_d$','$n_e$','$v_p$','HBN'], rr, width=0.8, edgecolor=\"white\",color=c, linewidth=0.5)\n",
    "ax.bar(['$\\gamma_d$','$n_e$','$v_p$','HBN'], rr, width=0.8, edgecolor=\"white\",color=c, linewidth=0.5)\n",
    "for index,data in enumerate(rr):\n",
    "    plt.text(x=index-0.02,y=data+0.005, s= \"{:.2f}\".format(data) , fontdict=dict(fontsize=14))\n",
    "ax.set( ylim=(0.6, 1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot for yUCS\n",
    "rr=[0,0,0,0]\n",
    "for j in range(dim):\n",
    "  temp=arrayX[:,j]*arrayyUCS[:]\n",
    "  temp1=np.power(arrayX[:,j],2)\n",
    "  temp2=np.power(arrayyUCS,2)\n",
    "  rr[j]=(np.sum(temp)/np.sqrt(np.sum(temp1)*np.sum(temp2)))\n",
    "print(rr)\n",
    "  # plot\n",
    "fig, ax = plt.subplots()\n",
    "# c = ['red', 'green', 'orange', 'blue']\n",
    "ax.bar(['$\\gamma_d$','$n_e$','$v_p$','HBN'], rr, width=0.8, edgecolor=\"white\",color=c, linewidth=0.5)\n",
    "for index,data in enumerate(rr):\n",
    "    plt.text(x=index-0.02,y=data+0.005, s= \"{:.2f}\".format(data) , fontdict=dict(fontsize=14))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def runBaseAlgorithms(X,y):# type(X)\n",
    "  print(\"runBaseAlgorithms function  is running...\")\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "  print(X_train.shape)\n",
    "  from sklearn.preprocessing import MinMaxScaler\n",
    "  scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "  scalarX.fit(X_train)\n",
    "  # scalarY.fit(y_train.values.reshape(-1,1))\n",
    "  X_train = scalarX.transform(X_train)\n",
    "  \n",
    "  # get the models to evaluate\n",
    "  models = get_models()\n",
    "  print('models='.format(models))\n",
    "  # evaluate the models and store results\n",
    "  results, names = list(), list()\n",
    "  i=1\n",
    "  executionTime= dict()\n",
    "  for name, model in models.items():\n",
    "      tunnedModel, executionTime[name]=get_bestParm(name,model,X_train,y_train.ravel(),[])\n",
    "      models[name]=tunnedModel\n",
    "      print('&&&&')\n",
    "      print(tunnedModel)\n",
    "      print('&&&&')\n",
    "          \n",
    "  \n",
    "  print(models)\n",
    "  print('executionTime={0}', executionTime)\n",
    "  predictedY=np.zeros((len(models),len(y_test)))\n",
    "  PredictedYTrain=np.zeros((len(models),len(y_train)))\n",
    "    # np.zeros((len(models),len(y_train)))\n",
    "  mae=dict()\n",
    "  mse=dict()\n",
    "  rmse=dict()\n",
    "  r2=dict()\n",
    "  VAF=dict()\n",
    "  MAPE=dict()   \n",
    "  A20=dict() \n",
    "  CI=dict() \n",
    "  IOS=dict()\n",
    "  WMAPE=dict()  \n",
    "  IOA=dict()\n",
    "\n",
    "  maeTrain=dict()\n",
    "  mseTrain=dict()\n",
    "  rmseTrain=dict()\n",
    "  r2Train=dict() \n",
    "  VAFTrain=dict() \n",
    "  MAPETrain=dict()   \n",
    "  A20Train=dict() \n",
    "  CITrain=dict()      \n",
    "\n",
    "  i=0\n",
    "  X_test  = scalarX.transform(X_test)\n",
    "  for name, model in models.items():\n",
    "      predictedYModel,mae[name],mse[name],rmse[name],r2[name],history,yhatTrain,evaluator = evaluate_model(model,X_train, X_test, y_train.ravel(), y_test.ravel())\n",
    "\n",
    "      VAF[name]=evaluator.VAF(multi_output=\"raw_values\")\n",
    "      MAPE[name]=evaluator.MAPE(multi_output=\"raw_values\")\n",
    "      A20[name]=evaluator.A20(multi_output=\"raw_values\")\n",
    "      CI[name]=evaluator.CI(multi_output=\"raw_values\")\n",
    "      IOS[name]=rmse[name]/np.mean(y_test.ravel())\n",
    "      WMAPE[name]=weighted_mean_absolute_percentage_error(predictedYModel,y_test.ravel())\n",
    "      IOA[name]=index_of_agreement(predictedYModel, y_test.ravel())\n",
    "\n",
    "      maeTrain[name] = metrics.mean_absolute_error(y_train.ravel(), yhatTrain)\n",
    "      mseTrain[name] = metrics.mean_squared_error(y_train.ravel(), yhatTrain)\n",
    "      rmseTrain [name]= np.sqrt(mseTrain[name])\n",
    "      r2Train[name] = metrics.r2_score(y_train.ravel(),yhatTrain)\n",
    "      evaluatorTrain=RegressionMetric(y_train.ravel(),yhatTrain)\n",
    "      VAFTrain[name] =evaluatorTrain.VAF(multi_output=\"raw_values\")\n",
    "      MAPETrain[name]=evaluatorTrain.MAPE(multi_output=\"raw_values\")\n",
    "      A20Train[name]=evaluatorTrain.A20(multi_output=\"raw_values\")\n",
    "      CITrain[name]=evaluatorTrain.CI(multi_output=\"raw_values\")\n",
    "\n",
    "      PredictedYTrain[i,:]=yhatTrain\n",
    "      # PredictedYTrain[name]=yhatTrain\n",
    "      # print(yhatTrain.shape)\n",
    "      # print(y_train.shape)\n",
    "      # print('---yhatTrain')\n",
    "      # print(yhatTrain)\n",
    "      # print('---y_train')\n",
    "      # print(y_train.ravel())\n",
    "      # print('---')\n",
    "      absoluteError=np.absolute(yhatTrain-y_train.ravel())\n",
    "      normalizedAbsoluteError=absoluteError/(np.max(absoluteError)+0.00001)\n",
    "      # print(normalizedAbsoluteError)\n",
    "      # weights = np.zeros((1,len(yhatTrain)))\n",
    "      weights=normalizedAbsoluteError/(1-normalizedAbsoluteError)\n",
    "      print('---')\n",
    "      if name=='DNN':\n",
    "        print(predictedYModel.shape)\n",
    "        predictedYModel=predictedYModel.reshape(len(y_test),)\n",
    "        print(predictedYModel.shape)\n",
    "      predictedY[i,:]=predictedYModel\n",
    "      results.append(rmse[name])\n",
    "      names.append(name)\n",
    "      print('>%s %.3f,%.3f,%.3f,%.3f,%.3f' % (name, mae[name],mse[name],rmse[name],r2[name],VAF[name]))\n",
    "      i=i+1\n",
    "  return mae,mse,rmse,r2,normalizedAbsoluteError,weights,models,X_train,X_test,y_train,y_test,predictedY,PredictedYTrain, maeTrain, mseTrain,rmseTrain,r2Train,VAF,VAFTrain,MAPE,MAPETrain,CI,CITrain,A20,A20Train,IOS,WMAPE,IOA\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def GridSearch_table_plot(grid_clf, param_name,\n",
    "                          num_results=15,\n",
    "                          negative=True,\n",
    "                          graph=True,\n",
    "                          display_all_params=True):\n",
    "    print(\"GridSearch_table_plot function is running...\")\n",
    "    '''Display grid search results\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "\n",
    "    grid_clf           the estimator resulting from a grid search\n",
    "                       for example: grid_clf = GridSearchCV( ...\n",
    "\n",
    "    param_name         a string with the name of the parameter being tested\n",
    "\n",
    "    num_results        an integer indicating the number of results to display\n",
    "                       Default: 15\n",
    "\n",
    "    negative           boolean: should the sign of the score be reversed?\n",
    "                       scoring = 'neg_log_loss', for instance\n",
    "                       Default: True\n",
    "\n",
    "    graph              boolean: should a graph be produced?\n",
    "                       non-numeric parameters (True/False, None) don't graph well\n",
    "                       Default: True\n",
    "\n",
    "    display_all_params boolean: should we print out all of the parameters, not just the ones searched for?\n",
    "                       Default: True\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "\n",
    "    GridSearch_table_plot(grid_clf, \"min_samples_leaf\")\n",
    "\n",
    "                          '''\n",
    "    from matplotlib      import pyplot as plt\n",
    "    from IPython.display import display\n",
    "    import pandas as pd\n",
    "\n",
    "    clf = grid_clf.best_estimator_\n",
    "    clf_params = grid_clf.best_params_\n",
    "    if negative:\n",
    "        clf_score = -grid_clf.best_score_\n",
    "    else:\n",
    "        clf_score = grid_clf.best_score_\n",
    "    clf_stdev = grid_clf.cv_results_['std_test_score'][grid_clf.best_index_]\n",
    "    cv_results = grid_clf.cv_results_\n",
    "\n",
    "    print(\"best parameters: {}\".format(clf_params))\n",
    "    print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n",
    "    if display_all_params:\n",
    "        import pprint\n",
    "        pprint.pprint(clf.get_params())\n",
    "\n",
    "    # pick out the best results\n",
    "    # =========================\n",
    "    scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    if negative:\n",
    "        best_mean = -best_row['mean_test_score']\n",
    "    else:\n",
    "        best_mean = best_row['mean_test_score']\n",
    "    best_stdev = best_row['std_test_score']\n",
    "    best_param = best_row['param_' + param_name]\n",
    "\n",
    "    # display the top 'num_results' results\n",
    "    # =====================================\n",
    "    display(pd.DataFrame(cv_results)             .sort_values(by='rank_test_score').head(num_results))\n",
    "\n",
    "    # plot the results\n",
    "    # ================\n",
    "    scores_df = scores_df.sort_values(by='param_' + param_name)\n",
    "\n",
    "    if negative:\n",
    "        means = -scores_df['mean_test_score']\n",
    "    else:\n",
    "        means = scores_df['mean_test_score']\n",
    "    stds = scores_df['std_test_score']\n",
    "    params = scores_df['param_' + param_name]\n",
    "\n",
    "    # plot\n",
    "    if graph:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.errorbar(params, means, yerr=stds)\n",
    "\n",
    "        plt.axhline(y=best_mean + best_stdev, color='red')\n",
    "        plt.axhline(y=best_mean - best_stdev, color='red')\n",
    "        plt.plot(best_param, best_mean, 'or')\n",
    "\n",
    "        plt.title(param_name + \" vs Score\\nBest Score {:0.5f}\".format(clf_score))\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Score')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mae,mse,rmse,r2,normalizedAbsoluteError,weights,models,X_train,X_test,y_train,y_test,predictedY,PredictedYTrain,maeTrainE,mseTrainE,rmseTrainE,r2TrainE,VAFE,VAFTrainE,MAPEE,MAPETrainE,CIE,CITrainE,A20E,A20TrainE,IOSE,WMAPEE,IOAE=runBaseAlgorithms(X,y)\n",
    "maeyUCS,mseyUCS,rmseyUCS,r2yUCS,normalizedAbsoluteErroryUCS,weightsyUCS,modelsyUCS,X_train,X_test,y_trainyUCS,y_testyUCS,predictedyUCS,PredictedYTrainUCS,maeTrainUCS, mseTrainUCS,rmseTrainUCS,r2TrainUCS,VAFUCS,VAFTrainUCS,MAPEUCS,MAPETrainUCS,CIUCS,CITrainUCS,A20UCS,A20TrainUCS,IOSUCS,WMAPEUCS,IOAUCS=runBaseAlgorithms(X,yUCS)\n",
    "\n",
    "\n",
    "# print(X)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(maeTrainE, mseTrainE,rmseTrainE,r2TrainE, VAFTrainE, MAPETrainE,CITrainE,A20TrainE)\n",
    "print('^^^^^^^^^^^^^new metrics for E^^^^^^^^^^^^^')\n",
    "print(\"VAF={0},MAPE={1},CI(PI)={2},A20={3},IOS={4}, WMAPE={5}, IOA={6}\",VAFE,MAPEE,CIE,A20E,IOS, WMAPEUCS,IOAUCS, WMAPEE, IOAE)\n",
    "print('^^^^^^^^^^^^^^new metrics for UCS^^^^^^^^^^^^')\n",
    "# print(maeTrainUCS, mseTrainUCS,rmseTrainUCS,r2TrainUCS)\n",
    "print(\"VAF={0},MAPE={1},CI(PI)={2},A20={3},IOS={4}, WMAPE={5}, IOA={6}\",VAFUCS,MAPEUCS,CIUCS,A20UCS,IOS,WMAPEUCS,IOAUCS)\n",
    "print('^^^^^^^^^^^^^^*******^^^^^^^^^^^^')\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "for name in r2TrainE:\n",
    "  print(name,r2TrainE[name])\n",
    "for name in mseTrainE:\n",
    "  print(name,mseTrainE[name])\n",
    "for name in VAFTrainE:\n",
    "  print(name,VAFTrainE[name])\n",
    "\n",
    "# , mseTrainE,rmseTrainE,r2TrainE)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for name in r2TrainUCS:\n",
    "  print(name,r2TrainUCS[name])\n",
    "for name in mseTrainUCS:\n",
    "  print(name,mseTrainUCS[name])\n",
    "for name in VAFTrainUCS:\n",
    "  print(name,VAFTrainUCS[name])\n",
    "# , mseTrainE,rmseTrainE,r2TrainE)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# (pd.DataFrame.from_dict(data=VAFUCS,orinet='')).to_csv('VAFUCS.csv')\n",
    "# (pd.DataFrame.from_dict(data=maeyUCS)).to_csv('maeE.csv')\n",
    "# (pd.DataFrame.from_dict(data=CIUCS)).to_csv('CIUCS.csv')\n",
    "# (pd.DataFrame.from_dict(data=A20UCS)).to_csv('A20UCS.csv')\n",
    "# (pd.DataFrame.from_dict(data=MAPEUCS)).to_csv('MAPEUCS.csv')\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# scores_mean=[[0.62879967, 0.65522623, 0.62041626, 0.64972037, 0.60425748 ,0.6534937,  0.56108763 ,0.63067605, 0.50905696, 0.59100625] [0.43925092, 0.55022683, 0.43260782, 0.53965881, 0.40668475 ,0.52305652 , 0.37584775 ,0.50523751 0.35346637 0.49098451]]\n",
    "# bestValue=np.amax(scores_mean, axis=1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plotScatter(x,y,outputLabel,name,r2,offset):\n",
    "  print(\"plotScatter function is running...\")\n",
    "  _, ax = plt.subplots()\n",
    "  ax.set_frame_on(True)\n",
    "  ax.tick_params(direction='out')\n",
    "  ax.set_facecolor(\"white\")\n",
    "  ax.set_axis_on()\n",
    "  # plt.rcParams[\"legend.loc\"] = 'best'\n",
    "  plt.rcParams['axes.unicode_minus'] = False\n",
    "  plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "  plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "  plt.grid(False)\n",
    "  plt.plot(x, y, 'o')\n",
    "  m, b = np.polyfit(x, y, 1)\n",
    "  plt.plot(x, m*x + b)\n",
    "  plt.plot(x, x,'k',linestyle='dashed')\n",
    "  ax.set_xlabel(outputLabel+' (observed)', fontsize=14 , fontweight='normal')\n",
    "  ax.set_ylabel(outputLabel+ ' (predicted)', fontsize=14 , fontweight='normal')\n",
    "  plt.title(name, fontsize=14 , fontweight='normal')\n",
    "  #  str(m)+'*X+'+str(b)\n",
    "  relation=\"$R^2$={:.2f}\\nY={:.2f}X+{:.2f}\".format(r2,m, b)\n",
    "  ax.text(np.min(x)+offset[0], np.max(y)-offset[1], relation , fontsize=14 , fontweight='normal', fontfamily='Times New Roman Cyr')\n",
    "  # , bbox=dict(facecolor='red', alpha=0.5)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# comment permanently\n",
    "# plotScatter(y_testyUCS,yhatUCS2,'UCS','Stacked Ensemble',r2UCS2,[1,4])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# print(sortedValues)\n",
    "# importantIdexes=sortedIdx[len(sortedIdx)-13:len(sortedIdx)]\n",
    "# print(importantIdexes)\n",
    "# print('--')\n",
    "# print(sortedIdx)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# sorted_mse = dict( sorted(mse.items()))\n",
    "# print('Dictionary in descending order by value : ',sorted_mse)\n",
    "print('>sorted Results in MSE')\n",
    "{k: v for k, v in sorted(mse.items(), key=lambda item: item[1])}\n",
    "# print(sorted(mse.items()))\n",
    "# sorted_mse = dict( sorted(mse.items(), reverse=True))\n",
    "# print('Dictionary in descending order by value : ',sorted_mse)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print('>sorted Results in R2')\n",
    "{k: v for k, v in sorted(r2.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# \tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "# \treturn X,y\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking(models,metamodel):\n",
    "    print(\"get_stacking function is running...\")\n",
    "\n",
    "\t# define the base models\n",
    "    level0 = list()\n",
    "    for name,model in models.items():\n",
    "        level0.append((name, model))\n",
    "#     level0.append(('knn', models['knn']))\n",
    "#     level0.append(('MLP2', models['MLP2']))\n",
    "#     level0.append(('MLP', models['MLP']))\n",
    "#     level0.append(('cart', models['cart']))\n",
    "#     level0.append(('SVR',  models['SVR']))\n",
    "#     level0.append(('LR',  models['LR']))\n",
    "\t# define meta learner model\n",
    "#     level1=LinearRegression()\n",
    "#     level1 = RandomForestRegressor()\n",
    "#     level1 =SVR(kernel='rbf')\n",
    "    level1 =metamodel\n",
    "#     level1=MLPRegressor(max_iter=2000, random_state=1)\n",
    "#     MLPRegressor(max_iter=500);\n",
    "#     level1 = LinearRegression()\n",
    "\t# define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=3)\n",
    "    return model\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print('>sorted Results in MSE')\n",
    "{k: v for k, v in sorted(mse.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(np.min(normalizedAbsoluteError))\n",
    "print(np.max(normalizedAbsoluteError))\n",
    "plt.plot(normalizedAbsoluteError*10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def runStackedEnsemble(selectedModels,X_train,y_train,y_test,stackedName,metamodel):\n",
    "  print(\"runStackedEnsemble function is running...\")\n",
    "\n",
    "  stackModel= get_stacking(selectedModels,metamodel)\n",
    "  # estimator = KerasRegressor(build_fn=stackModel, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "  print('***')\n",
    "  # print(estimator)\n",
    "  print('***')\n",
    "  print(stackModel.get_params().keys())\n",
    "  # tunnedModel=get_bestParm('stacking_SVM',stackModel ,X_train,y_train.ravel(),[])\n",
    "  print(stackedName)\n",
    "  tunnedModel, executionTime=get_bestParm(stackedName,stackModel ,X_train,y_train.ravel(),[])\n",
    "  # print(tunnedModel)\n",
    "  # tunnedModel.fit(X_train,y_train.ravel())\n",
    "  yhat=tunnedModel.predict(X_test)\n",
    "  yhatTrain=tunnedModel.predict(X_train)\n",
    "  mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "  mse = metrics.mean_squared_error(y_test, yhat)\n",
    "  rmse = np.sqrt(mse)\n",
    "  r2 = metrics.r2_score(y_test,yhat)\n",
    "  print('>stackedDE %.3f,%.3f,%.3f,%.3f' % (mae,mse,rmse,r2))\n",
    "  \n",
    "    \n",
    "  return mae,mse,rmse,r2,yhat,tunnedModel,yhatTrain, executionTime\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "stackedName='stacking_SVM'\n",
    "metamodel=SVR(kernel='rbf')\n",
    "\n",
    "selectedModels=dict()\n",
    "selectedModels['SVR']= models['SVR']\n",
    "# selectedModels['kNN']=   models['kNN'] \n",
    "selectedModels['XGBoost']=   models['XGBoost'] \n",
    "maeE,mseE,rmseE,r2E,yhatE,tunnedModelE,yHatTrainE, executionTime=runStackedEnsemble(selectedModels,X_train,y_train,y_test,stackedName,metamodel)\n",
    "\n",
    "\n",
    "evaluator=RegressionMetric(y_test.to_numpy(), yhatE)\n",
    "print(evaluator.VAF(multi_output=\"raw_values\"), evaluator.MAPE(multi_output=\"raw_values\"), evaluator.CI(multi_output=\"raw_values\"),evaluator.A20(multi_output=\"raw_values\"))\n",
    "print('executionTime={0}',executionTime )\n",
    "\n",
    "\n",
    "# selectedModelsUCS1=dict()\n",
    "# # selectedModelsUCS1['XGB']= modelsyUCS['XGB']\n",
    "# selectedModelsUCS1['MLP']= modelsyUCS['MLP'] \n",
    "# # selectedModelsUCS1['SVR']= modelsyUCS['SVR'] \n",
    "# selectedModelsUCS1['RF']= modelsyUCS['RF']\n",
    "# selectedModelsUCS1['kNN']= modelsyUCS['kNN']\n",
    "# print('model1')\n",
    "# maeUCS1,mseUCS1,rmseUCS1,r2UCS1,yhatUCS1,tunnedModelUCS1=runStackedEnsemble(selectedModelsUCS1,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(maeE,mseE,rmseE,r2E)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(tunnedModelE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5385774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelUCS_based on Training Data\n",
      "runStackedEnsemble function is running...\n",
      "get_stacking function is running...\n",
      "***\n",
      "***\n",
      "dict_keys(['cv', 'estimators', 'final_estimator__activation', 'final_estimator__alpha', 'final_estimator__batch_size', 'final_estimator__beta_1', 'final_estimator__beta_2', 'final_estimator__early_stopping', 'final_estimator__epsilon', 'final_estimator__hidden_layer_sizes', 'final_estimator__learning_rate', 'final_estimator__learning_rate_init', 'final_estimator__max_fun', 'final_estimator__max_iter', 'final_estimator__momentum', 'final_estimator__n_iter_no_change', 'final_estimator__nesterovs_momentum', 'final_estimator__power_t', 'final_estimator__random_state', 'final_estimator__shuffle', 'final_estimator__solver', 'final_estimator__tol', 'final_estimator__validation_fraction', 'final_estimator__verbose', 'final_estimator__warm_start', 'final_estimator', 'n_jobs', 'passthrough', 'verbose', 'RF', 'MLP', 'RF__bootstrap', 'RF__ccp_alpha', 'RF__criterion', 'RF__max_depth', 'RF__max_features', 'RF__max_leaf_nodes', 'RF__max_samples', 'RF__min_impurity_decrease', 'RF__min_samples_leaf', 'RF__min_samples_split', 'RF__min_weight_fraction_leaf', 'RF__n_estimators', 'RF__n_jobs', 'RF__oob_score', 'RF__random_state', 'RF__verbose', 'RF__warm_start', 'MLP__activation', 'MLP__alpha', 'MLP__batch_size', 'MLP__beta_1', 'MLP__beta_2', 'MLP__early_stopping', 'MLP__epsilon', 'MLP__hidden_layer_sizes', 'MLP__learning_rate', 'MLP__learning_rate_init', 'MLP__max_fun', 'MLP__max_iter', 'MLP__momentum', 'MLP__n_iter_no_change', 'MLP__nesterovs_momentum', 'MLP__power_t', 'MLP__random_state', 'MLP__shuffle', 'MLP__solver', 'MLP__tol', 'MLP__validation_fraction', 'MLP__verbose', 'MLP__warm_start'])\n",
      "stacking_MLP\n",
      "get_bestParm function is running....\n",
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "newPlot_grid_search function is running...\n",
      "originalParmNames[0]=final_estimator__hidden_layer_sizes\n",
      "gridParm1=[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "name_param_1=Hidden Layer Sizes\n",
      "the best score of stacking_MLP =-11.316082243214671\n",
      ">stackedDE 2.867,12.157,3.487,0.714\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (14,1) (56,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m maeUCS3,mseUCS3,rmseUCS3,r2UCS3,yhatUCS3,tunnedModelUCS3,yHatTrainUCS3\u001b[38;5;241m=\u001b[39mrunStackedEnsemble(selectedModelsUCS3Train,X_train,y_trainyUCS,y_testyUCS,stackedName3,metamodel3)\n\u001b[0;32m     47\u001b[0m evaluator\u001b[38;5;241m=\u001b[39mRegressionMetric(y_testyUCS\u001b[38;5;241m.\u001b[39mto_numpy(), yHatTrainUCS3)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(evaluator\u001b[38;5;241m.\u001b[39mVAF(multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m), evaluator\u001b[38;5;241m.\u001b[39mMAPE(multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m), evaluator\u001b[38;5;241m.\u001b[39mCI(multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m),evaluator\u001b[38;5;241m.\u001b[39mA20(multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\permetrics\\regression.py:774\u001b[0m, in \u001b[0;36mRegressionMetric.variance_accounted_for\u001b[1;34m(self, y_true, y_pred, multi_output, force_finite, finite_value, **kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;124;03mVariance Accounted For between 2 signals (VAF): Best possible score is 100% (identical signal), bigger value is better. Range = (-inf, 100%]\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03mLink: https://www.dcsc.tudelft.nl/~jwvanwingerden/lti/doc/html/vaf.html\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;124;03m    result (float, int, np.ndarray): VAF metric for single column or multiple columns\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    773\u001b[0m y_true, y_pred, n_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_processed_data(y_true, y_pred)\n\u001b[1;32m--> 774\u001b[0m result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(y_true \u001b[38;5;241m-\u001b[39m y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(y_true, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_output_result(result, n_out, multi_output, force_finite, finite_value\u001b[38;5;241m=\u001b[39mfinite_value)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (14,1) (56,1) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n",
      "findfont: Font family 'Times New Roman Cyr' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# selectedModelsUCS2=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName='stacking_MLP'\n",
    "# metamodel=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCS2['MLP']= modelsyUCS['MLP'] \n",
    "# selectedModelsUCS2['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('model2')\n",
    "# maeUCS2,mseUCS2,rmseUCS2,r2UCS2,yhatUCS2,tunnedModelUCS2,yHatTrainUCS=runStackedEnsemble(selectedModelsUCS2,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "# print(maeUCS2,mseUCS2,rmseUCS2,r2UCS2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# print(maeUCS2,mseUCS2,rmseUCS2,r2UCS2)\n",
    "# print(tunnedModelUCS2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# selectedModelsUCSTrain=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName='stacking_MLP'\n",
    "# metamodel=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCSTrain['MLP']= modelsyUCS['MLP'] \n",
    "# selectedModelsUCSTrain['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('modelUCS_based on Training Data')\n",
    "# maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain,yhatUCS_basedOnTrain,tunnedModelUCS_basedOnTrain,yHatTrainUCS_basedOnTrain=runStackedEnsemble(selectedModelsUCSTrain,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "# print(maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "selectedModelsUCS3Train=dict()\n",
    "# selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "stackedName3='stacking_MLP'\n",
    "metamodel3=MLPRegressor(max_iter=4000, random_state=1)\n",
    "selectedModelsUCS3Train['RF']= modelsyUCS['RF'] \n",
    "selectedModelsUCS3Train['MLP']= modelsyUCS['MLP'] \n",
    "print('modelUCS_based on Training Data')\n",
    "maeUCS3,mseUCS3,rmseUCS3,r2UCS3,yhatUCS3,tunnedModelUCS3,yHatTrainUCS3, executationTimeUCS=runStackedEnsemble(selectedModelsUCS3Train,X_train,y_trainyUCS,y_testyUCS,stackedName3,metamodel3)\n",
    "evaluator=RegressionMetric(y_testyUCS.to_numpy(), yHatTrainUCS3)\n",
    "print(evaluator.VAF(multi_output=\"raw_values\"), evaluator.MAPE(multi_output=\"raw_values\"), evaluator.CI(multi_output=\"raw_values\"),evaluator.A20(multi_output=\"raw_values\"))\n",
    "print('executationTimeUCS={0}', executationTimeUCS)\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# selectedModelsUCS2=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName='stacking_MLP'\n",
    "# metamodel=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCS2['MLP']= modelsyUCS['MLP'] \n",
    "# selectedModelsUCS2['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('model2')\n",
    "# maeUCS2,mseUCS2,rmseUCS2,r2UCS2,yhatUCS2,tunnedModelUCS2,yHatTrainUCS=runStackedEnsemble(selectedModelsUCS2,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "# print(maeUCS2,mseUCS2,rmseUCS2,r2UCS2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# print(maeUCS2,mseUCS2,rmseUCS2,r2UCS2)\n",
    "# print(tunnedModelUCS2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# selectedModelsUCSTrain=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName='stacking_MLP'\n",
    "# metamodel=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCSTrain['MLP']= modelsyUCS['MLP'] \n",
    "# selectedModelsUCSTrain['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('modelUCS_based on Training Data')\n",
    "# maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain,yhatUCS_basedOnTrain,tunnedModelUCS_basedOnTrain,yHatTrainUCS_basedOnTrain=runStackedEnsemble(selectedModelsUCSTrain,X_train,y_trainyUCS,y_testyUCS,stackedName,metamodel)\n",
    "# print(maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "selectedModelsUCS3Train=dict()\n",
    "# selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "stackedName3='stacking_MLP'\n",
    "metamodel3=MLPRegressor(max_iter=4000, random_state=1)\n",
    "selectedModelsUCS3Train['RF']= modelsyUCS['RF'] \n",
    "selectedModelsUCS3Train['MLP']= modelsyUCS['MLP'] \n",
    "print('modelUCS_based on Training Data')\n",
    "maeUCS3,mseUCS3,rmseUCS3,r2UCS3,yhatUCS3,tunnedModelUCS3,yHatTrainUCS3, executationTimeUCS=runStackedEnsemble(selectedModelsUCS3Train,X_train,y_trainyUCS,y_testyUCS,stackedName3,metamodel3)\n",
    "\n",
    "\n",
    "evaluator=RegressionMetric(y_testyUCS.to_numpy(), yhatUCS3)\n",
    "print(evaluator.VAF(multi_output=\"raw_values\"), evaluator.MAPE(multi_output=\"raw_values\"), evaluator.CI(multi_output=\"raw_values\"),evaluator.A20(multi_output=\"raw_values\"))\n",
    "\n",
    "\n",
    "print(maeUCS3,mseUCS3,rmseUCS3,r2UCS3)\n",
    "print(tunnedModelUCS3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# selectedModelsUCS4Train=dict()\n",
    "# # selectedModelsUCS2['SVR']= modelsyUCS['SVR']\n",
    "# stackedName4='stacking_SVM'\n",
    "# # stackedName='stacking_SVM'\n",
    "# metamodel4=SVR(kernel='rbf')\n",
    "\n",
    "# # metamodel4=MLPRegressor(max_iter=4000, random_state=1)\n",
    "# selectedModelsUCS4Train['SVR']= modelsyUCS['SVR'] \n",
    "# selectedModelsUCS4Train['XGBoost']= modelsyUCS['XGBoost'] \n",
    "# print('modelUCS_based on Training Data')\n",
    "# maeUCS4_basedOnTrain,mseUCS4_basedOnTrain,rmseUCS4_basedOnTrain,r2UCS4_basedOnTrain,yhatUCS4_basedOnTrain,tunnedModelUCS4_basedOnTrain,yHatTrainUCS4_basedOnTrain=runStackedEnsemble(selectedModelsUCS4Train,X_train,y_trainyUCS,y_testyUCS,stackedName4,metamodel4)\n",
    "# print(maeUCS4_basedOnTrain,mseUCS4_basedOnTrain,rmseUCS4_basedOnTrain,r2UCS4_basedOnTrain)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# print(maeUCS_basedOnTrain,mseUCS_basedOnTrain,rmseUCS_basedOnTrain,r2UCS_basedOnTrain)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# tunnedModel=get_bestParm('stacking_SVM',stackModel ,X_train,y_train.ravel(),[])\n",
    "# tunnedModel=get_bestParm('stacking_DNN',stackModel ,X_train,y_train.ravel())\n",
    "# tunnedModel=stackModel\n",
    "# print(tunnedModel)\n",
    "# metamodel=SVR(kernel='rbf',C=0.7977,gamma= 0.0841)\n",
    "# modelm = get_stacking(selectedModels,metamodel)\n",
    "# print(modelm)\n",
    "# print('----')\n",
    "# print(stackModel)\n",
    "# mae[name],mse[name],rmse[name],r2[name] = evaluate_model(tunnedModel,X_train, X_test, y_train.ravel(), y_test.ravel())\n",
    "# print(tunnedModel)\n",
    "# tunnedModel.fit(X_train,y_train.ravel())\n",
    "# yhat=tunnedModel.predict(X_test)\n",
    "# mae = metrics.mean_absolute_error(y_test, yhat)\n",
    "# mse = metrics.mean_squared_error(y_test, yhat)\n",
    "# rmse = np.sqrt(mse)\n",
    "# r2 = metrics.r2_score(y_test,yhat)\n",
    "# print('Coefficient: %.1f',coefficient)\n",
    "# print('>stackedDE %.3f,%.3f,%.3f,%.3f' % (mae,mse,rmse,r2))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# print(r2)\n",
    "yhatUCS2=yhatUCS3\n",
    "r2UCS2=r2UCS3\n",
    "\n",
    "i=0\n",
    "for name in models.keys():\n",
    "  plotScatter(y_test,predictedY[i,:],'E',name,r2[name],[0,1])\n",
    "  i=i+1\n",
    "plotScatter(y_test,yhatE,'E','Stacking Ensemble',r2E,[0,1])\n",
    "\n",
    "i=0\n",
    "for name in modelsyUCS.keys():\n",
    "  plotScatter(y_testyUCS,predictedyUCS[i,:],'UCS',name,r2yUCS[name],[1,3])\n",
    "  i=i+1\n",
    "plotScatter(y_testyUCS,yhatUCS2,'UCS','Stacking Ensemble',r2UCS2,[1,4])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print('>sorted Results in R2')\n",
    "{k: v for k, v in sorted(r2.items(), key=lambda item: item[1])}\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def plotPredictedValues(predictedY,actualY,yLabel,models,predictedYStacked):\n",
    "  print(\"plotPredictedValues function is running...\")\n",
    "  _, ax = plt.subplots()\n",
    "  ax.set_frame_on(True)\n",
    "  ax.tick_params(direction='out')\n",
    "  ax.set_facecolor(\"white\")\n",
    "  ax.set_axis_on()\n",
    "  # plt.rcParams[\"legend.loc\"] = 'best'\n",
    "  plt.rcParams['axes.unicode_minus'] = False\n",
    "  plt.rcParams.update({'font.family':'Times New Roman Cyr'})\n",
    "  plt.rcParams.update({'axes.edgecolor':'k'})\n",
    "  plt.grid(False)\n",
    "  xValues=np.array(range(1,len(actualY)+1))\n",
    "  i=0\n",
    "  for name in models.keys():\n",
    "    plt.plot(xValues,predictedY[i,:], '^', label= name)\n",
    "    i=i+1\n",
    "  plt.plot(xValues,predictedYStacked, 'o', label= 'Stacking Ensemble')\n",
    "  plt.plot(xValues,actualY, 'k-', label= 'Observed')\n",
    "  xi = list(range(1,len(xValues)+1))\n",
    "  print('----')\n",
    "  print(xi)\n",
    "  print(xValues)\n",
    "  # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%this line is needed for test data \n",
    "  if len(actualY)<20:\n",
    "    plt.xticks(xi,xValues)\n",
    "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.16),\n",
    "      fancybox=True, shadow=True, ncol=2, prop={'family': 'Times New Roman Cyr'}, fontsize=14)\n",
    "  ax.set_frame_on(True)\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "  box = ax.get_position()\n",
    "  ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "  ax.set_xlabel('Data Points', fontsize=14 , fontweight='normal')\n",
    "  ax.set_ylabel( yLabel, fontsize=14 , fontweight='normal')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plotPredictedValues(predictedY,y_test,'E (GPa)',models,yhatE)\n",
    "# print(predictedY)\n",
    "\n",
    "plotPredictedValues(predictedyUCS,y_testyUCS,'UCS (MPa)',modelsyUCS,yhatUCS3)\n",
    "# print(predictedyUCS)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "plotPredictedValues(PredictedYTrain,y_train,'E (GPa)',models,yHatTrainE)\n",
    "# print(predictedY)\n",
    "\n",
    "yHatTrainUCS=yHatTrainUCS3\n",
    "plotPredictedValues(PredictedYTrainUCS,y_trainyUCS,'UCS (MPa)',modelsyUCS,yHatTrainUCS)\n",
    "# print(predictedyUCS)\n",
    "\n",
    "print(\"Doooooooooooooone\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
